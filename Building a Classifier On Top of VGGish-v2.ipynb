{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "\n",
    "* Separate out prediction, loading the model\n",
    "* Confirm audio samples are being loaded in a way that is extensible\n",
    "* Train with all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg\n",
    "#!python vggish_train_demo.py --num_batches 50 --train_vggish=False --checkpoint './vggish_model.ckpt'\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioUtils import readFolder\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting samples\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.845144\n",
      "Step 2: loss 0.744279\n",
      "Step 3: loss 0.680981\n",
      "Step 4: loss 0.648908\n",
      "Step 5: loss 0.619371\n",
      "[[0.38603973 0.5640656 ]\n",
      " [0.3811315  0.5746864 ]\n",
      " [0.38298747 0.57671666]\n",
      " ...\n",
      " [0.3830327  0.5694682 ]\n",
      " [0.3824789  0.5744395 ]\n",
      " [0.38392663 0.56973225]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def getFilePathsForClass(c, max):\n",
    "    dirs = readFolder('samples/%s' % (c))\n",
    "    collected_files = []\n",
    "    for d in dirs[:max]:\n",
    "        files = readFolder('samples/%s/%s/out' % (c, d))\n",
    "\n",
    "        for file in files:\n",
    "            collected_files.append('samples/%s/%s/out/%s' % (c, d, file))\n",
    "    return collected_files\n",
    "            \n",
    "def getSampleForFile(file):\n",
    "    return AudioSegment.from_file(file).get_array_of_samples()\n",
    "\n",
    "# accepts a numpy array representing a single audio file, or multiple files concat'ed together\n",
    "def getFileAsVggishInput(sample):\n",
    "    return vggish_input.waveform_to_examples(sample, 44100)\n",
    "\n",
    "# append every audio file into one enormous massive audio file\n",
    "def getSamplesForFiles(files):\n",
    "    sample = np.array([])\n",
    "    \n",
    "    for file in files:\n",
    "        audio = getSampleForFile(file)\n",
    "        sample = np.append(sample, audio)\n",
    "    return getFileAsVggishInput(sample) \n",
    "\n",
    "def getData(files, arr):\n",
    "    examples = getSamplesForFiles(files)\n",
    "    labels = np.array([arr] * examples.shape[0])\n",
    "    \n",
    "    return (examples, labels)\n",
    "\n",
    "def getOneHot(class_num, idx):\n",
    "    arr = np.zeros(class_num)\n",
    "    arr[idx] = 1\n",
    "    return arr\n",
    "\n",
    "def getSamples(classes, shuf = True, num = None):\n",
    "    exes = []\n",
    "    whys = []\n",
    "    print('collecting samples')\n",
    "    for idx, cls in enumerate(classes):\n",
    "        files = getFilePathsForClass(cls, num)\n",
    "        x, y = getData(files, getOneHot(len(classes), idx))\n",
    "        exes.append(x)\n",
    "        whys.append(y)\n",
    "    \n",
    "    all_examples = np.concatenate(exes)\n",
    "    all_labels = np.concatenate(whys)\n",
    "    labeled_examples = list(zip(all_examples, all_labels))\n",
    "    if shuf:\n",
    "        shuffle(labeled_examples)\n",
    "\n",
    "    # Separate and return the features and labels.\n",
    "    features = [example for (example, _) in labeled_examples]\n",
    "    labels = [label for (_, label) in labeled_examples]\n",
    "    return (features, labels)\n",
    "\n",
    "def train(get_examples, num, _NUM_BATCHES = 50):\n",
    "    _NUM_CLASSES = 2\n",
    "    model_name_to_save = './model/model_%s' % (num)    \n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        pred = None\n",
    "        # Define VGGish.\n",
    "        embeddings = vggish_slim.define_vggish_slim(True) # Do we train VGG-ish?\n",
    "\n",
    "        # Define a shallow classification model and associated training ops on top\n",
    "        # of VGGish.\n",
    "        with tf.variable_scope('mymodel'):\n",
    "            # Add a fully connected layer with 100 units.\n",
    "            num_units = 100\n",
    "            fc = slim.fully_connected(embeddings, num_units)\n",
    "\n",
    "            # Add a classifier layer at the end, consisting of parallel logistic\n",
    "            # classifiers, one per class. This allows for multi-class tasks.\n",
    "            logits = slim.fully_connected(\n",
    "              fc, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
    "            pred = tf.sigmoid(logits, name='prediction')\n",
    "\n",
    "            # Add training ops.\n",
    "            with tf.variable_scope('train'):\n",
    "                global_step = tf.Variable(\n",
    "                    0, name='global_step', trainable=False,\n",
    "                    collections=[tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                 tf.GraphKeys.GLOBAL_STEP])\n",
    "\n",
    "            # Labels are assumed to be fed as a batch multi-hot vectors, with\n",
    "            # a 1 in the position of each positive class label, and 0 elsewhere.\n",
    "            labels = tf.placeholder(\n",
    "                tf.float32, shape=(None, _NUM_CLASSES), name='labels')\n",
    "\n",
    "            # Cross-entropy label loss.\n",
    "            xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=logits, labels=labels, name='xent')\n",
    "            loss = tf.reduce_mean(xent, name='loss_op')\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "            # We use the same optimizer and hyperparameters as used to train VGGish.\n",
    "            optimizer = tf.train.AdamOptimizer(\n",
    "                learning_rate=vggish_params.LEARNING_RATE,\n",
    "                epsilon=vggish_params.ADAM_EPSILON)\n",
    "            optimizer.minimize(loss, global_step=global_step, name='train_op')\n",
    "\n",
    "        # Initialize all variables in the model, and then load the pre-trained\n",
    "        # VGGish checkpoint.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, './vggish_model.ckpt')\n",
    "\n",
    "        # Locate all the tensors and ops we need for the training loop.\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.INPUT_TENSOR_NAME)\n",
    "        #for op in tf.get_default_graph().get_operations():\n",
    "            #print(str(op.name))\n",
    "\n",
    "        labels_tensor = sess.graph.get_tensor_by_name('mymodel/labels:0')\n",
    "        #labels_tensor = sess.graph.get_tensor_by_name('mymodel/train/labels:0')    \n",
    "        global_step_tensor = sess.graph.get_tensor_by_name(\n",
    "            'mymodel/train/global_step:0')\n",
    "        loss_tensor = sess.graph.get_tensor_by_name('mymodel/loss_op:0')\n",
    "        train_op = sess.graph.get_operation_by_name('mymodel/train_op')\n",
    "\n",
    "        # The training loop.\n",
    "        for _ in range(_NUM_BATCHES):\n",
    "            (features, labels) = get_examples(num, shuf=True)\n",
    "            [num_steps, loss, _] = sess.run(\n",
    "                [global_step_tensor, loss_tensor, train_op],\n",
    "                feed_dict={features_tensor: features, labels_tensor: labels})\n",
    "            print('Step %d: loss %g' % (num_steps, loss))\n",
    "            saver = tf.train.Saver()\n",
    "            saver.save(sess, model_name_to_save)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.OUTPUT_TENSOR_NAME)\n",
    "        prediction=tf.argmax(logits,1)\n",
    "        (features, labels) = get_examples(num, shuf=False)\n",
    "        embedding_batch = sess.run(pred, feed_dict={features_tensor: features})\n",
    "        return embedding_batch \n",
    "\n",
    "def getSavedSamples(num, shuf = True):\n",
    "    features_name = 'checkpoints/features_%s.npy' % (num)\n",
    "    labels_name = 'checkpoints/labels_%s.npy' % (num)\n",
    "    features = np.load(features_name)\n",
    "    labels = np.load(labels_name)\n",
    "\n",
    "    labeled_examples = list(zip(features, labels))\n",
    "    if shuf:\n",
    "        shuffle(labeled_examples)\n",
    "\n",
    "    # Separate and return the features and labels.\n",
    "    features = [example for (example, _) in labeled_examples]\n",
    "    labels = [label for (_, label) in labeled_examples]\n",
    "    return (features, labels)\n",
    "\n",
    "def trainAndSaveAndPredict(number_of_samples = 1, epochs = 5):\n",
    "    features_name = 'checkpoints/features_%s.npy' % (number_of_samples)\n",
    "    labels_name = 'checkpoints/labels_%s.npy' % (number_of_samples)\n",
    "    \n",
    "    if not os.path.isfile(features_name) or not os.path.isfile(labels_name):\n",
    "        print('no files saved for %s' % number_of_samples)\n",
    "        (features, labels) = getSamples(['laughter', 'notlaughter'], shuf = False, num = number_of_samples)\n",
    "        np.save('checkpoints/features_%s.npy' % (number_of_samples), features)\n",
    "        np.save('checkpoints/labels_%s.npy' % (number_of_samples), labels)\n",
    "\n",
    "    preds = train(getSavedSamples, number_of_samples, epochs)\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        print(preds)\n",
    "        print(sess.run(tf.argmax(input=preds, axis=1)))\n",
    "\n",
    "trainAndSaveAndPredict(number_of_samples = 3, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
