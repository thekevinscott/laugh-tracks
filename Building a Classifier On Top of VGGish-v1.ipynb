{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg\n",
    "    wget https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "#!python vggish_train_demo.py --num_batches 50 --train_vggish=False --checkpoint './vggish_model.ckpt'\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioUtils import readFolder\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting laughter\n",
      "building data for files1\n",
      "collecting not laughter\n",
      "collecting notlaughter\n",
      "building data for files2\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "def collectFilesForClass(c, max):\n",
    "    dirs = readFolder('samples/%s' % (c))\n",
    "    collected_files = []\n",
    "    for d in dirs[:max]:\n",
    "        files = readFolder('samples/%s/%s/out' % (c, d))\n",
    "\n",
    "        for file in files:\n",
    "            collected_files.append('samples/%s/%s/out/%s' % (c, d, file))\n",
    "    return collected_files\n",
    "            \n",
    "def getSampleForFile(file):\n",
    "    return AudioSegment.from_file(file).get_array_of_samples()\n",
    "\n",
    "def getSamplesForFiles(files):\n",
    "    sample = np.array([])\n",
    "    \n",
    "    sr = 44100  # Sampling rate.\n",
    "    for file in files:\n",
    "        \n",
    "        sample = np.append(sample, getSampleForFile(file))\n",
    "    return vggish_input.waveform_to_examples(sample, sr)   \n",
    "\n",
    "def getData(files, arr):\n",
    "    examples = getSamplesForFiles(files)\n",
    "    labels = np.array([arr] * examples.shape[0])\n",
    "    \n",
    "    return (examples, labels)\n",
    "\n",
    "def get_samples(shuf = True, num = None):\n",
    "    #num_seconds = 5 * (len(files) * 2)\n",
    "    #t = np.linspace(0, num_seconds, int(num_seconds * sr))  # Time axis.\n",
    "    \n",
    "    print('collecting laughter')\n",
    "    files1 = collectFilesForClass('laughter', num)\n",
    "    print('building data for files1')    \n",
    "    x1, y1 = getData(files1, [1, 0])\n",
    "    print('collecting not laughter')\n",
    "\n",
    "    print('collecting notlaughter')\n",
    "    files2 = collectFilesForClass('notlaughter', num)\n",
    "    print('building data for files2')    \n",
    "    x2, y2 = getData(files2, [0, 1])\n",
    "    \n",
    "    all_examples = np.concatenate((x1, x2))\n",
    "    all_labels = np.concatenate((y1, y2))\n",
    "    labeled_examples = list(zip(all_examples, all_labels))\n",
    "    if shuf:\n",
    "        shuffle(labeled_examples)\n",
    "\n",
    "    # Separate and return the features and labels.\n",
    "    features = [example for (example, _) in labeled_examples]\n",
    "    labels = [label for (_, label) in labeled_examples]\n",
    "    return (features, labels)\n",
    "\n",
    "num = 2\n",
    "(features, labels) = get_samples(shuf = False, num = num)\n",
    "print(len(features))\n",
    "np.save('features_%s.npy' % (num), features)\n",
    "np.save('labels_%s.npy' % (num), labels)\n",
    "# returns 3 classes, 5 sampels each, 96 numbers each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: ./vggish_model.ckpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7fdbd8799bf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetSavedSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7fdbd8799bf0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(get_examples, _NUM_BATCHES)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# VGGish checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mvggish_slim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vggish_slim_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./vggish_model.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Locate all the tensors and ops we need for the training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/vggish_slim.py\u001b[0m in \u001b[0;36mload_vggish_slim_checkpoint\u001b[0;34m(session, checkpoint_path)\u001b[0m\n\u001b[1;32m    127\u001b[0m   saver = tf.train.Saver(vggish_vars, name='vggish_load_pretrained',\n\u001b[1;32m    128\u001b[0m                          write_version=1)\n\u001b[0;32m--> 129\u001b[0;31m   \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \"\n\u001b[0;32m-> 1717\u001b[0;31m                        + compat.as_text(save_path))\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: ./vggish_model.ckpt"
     ]
    }
   ],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "_NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "def train(get_examples, _NUM_BATCHES = 50):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        pred = None\n",
    "        # Define VGGish.\n",
    "        embeddings = vggish_slim.define_vggish_slim(True) # Do we train VGG-ish?\n",
    "\n",
    "        # Define a shallow classification model and associated training ops on top\n",
    "        # of VGGish.\n",
    "        with tf.variable_scope('mymodel'):\n",
    "            # Add a fully connected layer with 100 units.\n",
    "            num_units = 100\n",
    "            fc = slim.fully_connected(embeddings, num_units)\n",
    "\n",
    "            # Add a classifier layer at the end, consisting of parallel logistic\n",
    "            # classifiers, one per class. This allows for multi-class tasks.\n",
    "            logits = slim.fully_connected(\n",
    "              fc, _NUM_CLASSES, activation_fn=None, scope='logits')\n",
    "            pred = tf.sigmoid(logits, name='prediction')\n",
    "\n",
    "            # Add training ops.\n",
    "            with tf.variable_scope('train'):\n",
    "                global_step = tf.Variable(\n",
    "                    0, name='global_step', trainable=False,\n",
    "                    collections=[tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                 tf.GraphKeys.GLOBAL_STEP])\n",
    "\n",
    "            # Labels are assumed to be fed as a batch multi-hot vectors, with\n",
    "            # a 1 in the position of each positive class label, and 0 elsewhere.\n",
    "            labels = tf.placeholder(\n",
    "                tf.float32, shape=(None, _NUM_CLASSES), name='labels')\n",
    "\n",
    "            # Cross-entropy label loss.\n",
    "            xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=logits, labels=labels, name='xent')\n",
    "            loss = tf.reduce_mean(xent, name='loss_op')\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "            # We use the same optimizer and hyperparameters as used to train VGGish.\n",
    "            optimizer = tf.train.AdamOptimizer(\n",
    "                learning_rate=vggish_params.LEARNING_RATE,\n",
    "                epsilon=vggish_params.ADAM_EPSILON)\n",
    "            optimizer.minimize(loss, global_step=global_step, name='train_op')\n",
    "\n",
    "        # Initialize all variables in the model, and then load the pre-trained\n",
    "        # VGGish checkpoint.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, './vggish_model.ckpt')\n",
    "\n",
    "        # Locate all the tensors and ops we need for the training loop.\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.INPUT_TENSOR_NAME)\n",
    "        #for op in tf.get_default_graph().get_operations():\n",
    "            #print(str(op.name))\n",
    "\n",
    "        labels_tensor = sess.graph.get_tensor_by_name('mymodel/labels:0')\n",
    "        #labels_tensor = sess.graph.get_tensor_by_name('mymodel/train/labels:0')    \n",
    "        global_step_tensor = sess.graph.get_tensor_by_name(\n",
    "            'mymodel/train/global_step:0')\n",
    "        loss_tensor = sess.graph.get_tensor_by_name('mymodel/loss_op:0')\n",
    "        train_op = sess.graph.get_operation_by_name('mymodel/train_op')\n",
    "\n",
    "        # The training loop.\n",
    "        for _ in range(_NUM_BATCHES):\n",
    "          (features, labels) = get_examples(shuf=True)\n",
    "          [num_steps, loss, _] = sess.run(\n",
    "              [global_step_tensor, loss_tensor, train_op],\n",
    "              feed_dict={features_tensor: features, labels_tensor: labels})\n",
    "          print('Step %d: loss %g' % (num_steps, loss))\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './model/model_%s' %s (num))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #pproc = vggish_postprocess.Postprocessor('./vggish_pca_params.npz')\n",
    "        #print(vggish_params)\n",
    "        # Define the model in inference mode, load the checkpoint, and\n",
    "        # locate input and output tensors.\n",
    "        #vggish_slim.define_vggish_slim(training=False)\n",
    "        #vggish_slim.load_vggish_slim_checkpoint(sess, './vggish_model.ckpt')\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.OUTPUT_TENSOR_NAME)\n",
    "        prediction=tf.argmax(logits,1)\n",
    "        (features, labels) = get_examples(shuf=False)\n",
    "        print(labels)\n",
    "        #best = sess.run([prediction],feed_dict)\n",
    "        # Run inference and postprocessing.\n",
    "        embedding_batch = sess.run(pred,\n",
    "                                     feed_dict={features_tensor: features})\n",
    "        #print(embedding_batch.shape)\n",
    "        #print(embedding_batch)\n",
    "        #preds = sess.run(tf.nn.softmax(embedding_batch[0], 1))\n",
    "        #print(preds)\n",
    "        #preds=tf.argmax(embedding_batch,1)\n",
    "        #print(preds.eval(feed_dict={features_tensor: features}))\n",
    "        return embedding_batch \n",
    "    \n",
    "def getSavedSamples(shuf = True):\n",
    "    features = np.load('features_%s.npy' % (num))\n",
    "    labels = np.load('labels_%s.npy' % (num))\n",
    "    \n",
    "    labeled_examples = list(zip(features, labels))\n",
    "    if shuf:\n",
    "        shuffle(labeled_examples)\n",
    "\n",
    "    # Separate and return the features and labels.\n",
    "    features = [example for (example, _) in labeled_examples]\n",
    "    labels = [label for (_, label) in labeled_examples]\n",
    "    return (features, labels)\n",
    "\n",
    "preds = train(getSavedSamples, 50)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    print(preds)\n",
    "    print(sess.run(tf.argmax(input=preds, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vggish_postprocess\n",
    "\n",
    "(features, labels) = _get_examples_batch2()\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    pproc = vggish_postprocess.Postprocessor('./vggish_pca_params.npz')\n",
    "    # Define the model in inference mode, load the checkpoint, and\n",
    "    # locate input and output tensors.\n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, './vggish_model.ckpt')\n",
    "    features_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "    # Run inference and postprocessing.\n",
    "    [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: features})\n",
    "    print(embedding_batch)\n",
    "    postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "    print(postprocessed_batch)\n",
    "\n",
    "    # Write the postprocessed embeddings as a SequenceExample, in a similar\n",
    "    # format as the features released in AudioSet. Each row of the batch of\n",
    "    # embeddings corresponds to roughly a second of audio (96 10ms frames), and\n",
    "    # the rows are written as a sequence of bytes-valued features, where each\n",
    "    # feature value contains the 128 bytes of the whitened quantized embedding.\n",
    "    seq_example = tf.train.SequenceExample(\n",
    "        feature_lists=tf.train.FeatureLists(\n",
    "            feature_list={\n",
    "                vggish_params.AUDIO_EMBEDDING_FEATURE_NAME:\n",
    "                    tf.train.FeatureList(\n",
    "                        feature=[\n",
    "                            tf.train.Feature(\n",
    "                                bytes_list=tf.train.BytesList(\n",
    "                                    value=[embedding.tobytes()]))\n",
    "                            for embedding in postprocessed_batch\n",
    "                        ]\n",
    "                    )\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(seq_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = [\n",
    "    '%s/0.000000_5.000000.wav' % (directory),\n",
    "    '%s/5.000000_10.000000.wav' % (directory),\n",
    "    '%s/10.000000_15.000000.wav' % (directory),\n",
    "    #'%s/15.000000_20.000000.wav' % (directory),\n",
    "    #'%s/20.000000_25.000000.wav' % (directory),    \n",
    "]\n",
    "def _get_examples_batch2(shuf = True):\n",
    "    \"\"\"Returns a shuffled batch of examples of all audio classes.\n",
    "\n",
    "    Note that this is just a toy function because this is a simple demo intended\n",
    "    to illustrate how the training code might work.\n",
    "\n",
    "    Returns:\n",
    "    a tuple (features, labels) where features is a NumPy array of shape\n",
    "    [batch_size, num_frames, num_bands] where the batch_size is variable and\n",
    "    each row is a log mel spectrogram patch of shape [num_frames, num_bands]\n",
    "    suitable for feeding VGGish, while labels is a NumPy array of shape\n",
    "    [batch_size, num_classes] where each row is a multi-hot label vector that\n",
    "    provides the labels for corresponding rows in features.\n",
    "    \"\"\"\n",
    "    # Make a waveform for each class.\n",
    "    num_seconds = 5 * (len(files) * 2)\n",
    "    \n",
    "    sr = 44100  # Sampling rate.\n",
    "    t = np.linspace(0, num_seconds, int(num_seconds * sr))  # Time axis.\n",
    "    \n",
    "    # White noise.\n",
    "    noise = np.random.normal(-1, 1, size=t.shape)\n",
    "\n",
    "    sample = np.array([])\n",
    "    for file in files:\n",
    "        sample = np.append(sample, AudioSegment.from_file(file).get_array_of_samples())\n",
    "    #sample = np.array(samples)\n",
    "    \n",
    "    #print(first_sample.shape)\n",
    "    #sine_examples = []\n",
    "    #for file in files:\n",
    "    #    sine_examples.append(AudioSegment.from_file(files[0]).get_array_of_samples()[:96])\n",
    "\n",
    "    #sine_examples = np.array(sine_examples)\n",
    "    # Random sine wave.\n",
    "\n",
    "    # Make examples of each signal and corresponding labels.\n",
    "    # Sine is class index 0, Const class index 1, Noise class index 2.\n",
    "    sine_examples = vggish_input.waveform_to_examples(sample, sr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #freq = np.random.uniform(100, 1000)\n",
    "    #sine = np.sin(2 * np.pi * freq * t)\n",
    "    #magnitude = np.random.uniform(-1, 1)\n",
    "    #print(magnitude)\n",
    "    #const = -1 * t\n",
    "    # Random constant signal.\n",
    "    #magnitude2 = np.random.uniform(-1, 1)\n",
    "    #print(magnitude2)\n",
    "    #const2 = 0 * t\n",
    "    # White noise.\n",
    "    noise = np.random.normal(-1, 1, size=t.shape)\n",
    "\n",
    "    # Make examples of each signal and corresponding labels.\n",
    "    # Sine is class index 0, Const class index 1, Noise class index 2.\n",
    "    #sine_examples = vggish_input.waveform_to_examples(const, sr)\n",
    "    sine_labels = np.array([[1, 0]] * sine_examples.shape[0])\n",
    "    #sine_examples2 = vggish_input.waveform_to_examples(const2, sr)\n",
    "    #sine_labels2 = np.array([[0, 1]] * sine_examples.shape[0])    \n",
    "    #const_examples = vggish_input.waveform_to_examples(const, sr)\n",
    "    #const_labels = np.array([[0, 1, 0]] * const_examples.shape[0])\n",
    "    noise_examples = vggish_input.waveform_to_examples(noise, sr)\n",
    "    noise_labels = np.array([[0, 1]] * noise_examples.shape[0])\n",
    "\n",
    "    #print(sine_examples[0])\n",
    "    #print('---')\n",
    "    #print(sine_examples2[0])\n",
    "\n",
    "    #print(noise_examples.shape)\n",
    "\n",
    "    # Shuffle (example, label) pairs across all classes.\n",
    "    all_examples = np.concatenate((sine_examples, noise_examples))\n",
    "    all_labels = np.concatenate((sine_labels, noise_labels))\n",
    "    labeled_examples = list(zip(all_examples, all_labels))\n",
    "    if shuf:\n",
    "        shuffle(labeled_examples)\n",
    "\n",
    "    # Separate and return the features and labels.\n",
    "    features = [example for (example, _) in labeled_examples]\n",
    "    labels = [label for (_, label) in labeled_examples]\n",
    "    return (features, labels)\n",
    "\n",
    "(features, labels) = _get_examples_batch2()\n",
    "print(len(features))\n",
    "# returns 3 classes, 5 sampels each, 96 numbers each"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
