{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg -y\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_pca_params.npz\n",
    "#installDeps()\n",
    "#!python vggish_train_demo.py --num_batches 50 --train_vggish=False --checkpoint './vggish_model.ckpt'\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioModel import predict, train\n",
    "from audioInput import getLaughTracks, getNoise\n",
    "from audioUtils import readFolder\n",
    "\n",
    "def getModel(path):\n",
    "    files = readFolder('model/%s' % path)\n",
    "    if len(files) > 0:\n",
    "        return '%s/%s' % (path, files[0])\n",
    "    return None\n",
    "\n",
    "def trainAndSaveAndPredict(test_data, model, number_of_classes = 2, number_of_samples = 1, epochs = 5, getData = getLaughTracks, log = True):\n",
    "    model_name = '%s_%s' % (model, number_of_samples)\n",
    "    def curriedGetSamples(shuf):\n",
    "        return getData(number_of_samples = number_of_samples, shuf = shuf, log = log)\n",
    "    print('model_name', model_name)\n",
    "    preds = train(curriedGetSamples, number_of_classes, model_name = model_name, epochs = epochs)\n",
    "    \n",
    "    return predict(getModel('%s' % (model_name)), number_of_classes, test_data)\n",
    "\n",
    "def printResults(preds, expected = None): \n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        print(preds)\n",
    "        print(sess.run(tf.argmax(input=preds, axis=1))) \n",
    "        print('expected results', expected)\n",
    "\n",
    "def trainForNoise(number_of_samples=5, epochs=5):\n",
    "    print('training on noise, sin, and constant waves')\n",
    "    (features, labels) = getNoise(shuf=False, number_of_samples = 2)\n",
    "    preds = trainAndSaveAndPredict(features, 'noise', number_of_classes = 3, number_of_samples = number_of_samples, epochs = epochs, getData = getNoise)\n",
    "    printResults(preds, [0, 0, 1, 1, 2, 2])\n",
    "    \n",
    "def trainForLaughter(number_of_samples=5, epochs=5):  \n",
    "    #print('training on laughter and not laughter')\n",
    "    (features, labels) = getLaughTracks(shuf=False, number_of_samples = 2, log=False)\n",
    "    preds = trainAndSaveAndPredict(features, 'audio', number_of_classes = 2, number_of_samples = number_of_samples, epochs = epochs, getData = getLaughTracks, log = False)\n",
    "    printResults(preds, [0, 0, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainForLaughter(number_of_samples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range (0, 30):\n",
    "#    number_of_samples = 1006 + (i * 1)\n",
    "#    trainForLaughter(number_of_samples=number_of_samples, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name audio_100\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.738319\n",
      "saving model ./model/audio_100/1_20/model\n",
      "Step 2: loss 0.703907\n",
      "saving model ./model/audio_100/2_20/model\n",
      "Step 3: loss 0.680426\n",
      "saving model ./model/audio_100/3_20/model\n",
      "Step 4: loss 0.686973\n",
      "saving model ./model/audio_100/4_20/model\n",
      "Step 5: loss 0.671367\n",
      "saving model ./model/audio_100/5_20/model\n",
      "Step 6: loss 0.670204\n",
      "saving model ./model/audio_100/6_20/model\n",
      "Step 7: loss 0.656642\n",
      "saving model ./model/audio_100/7_20/model\n",
      "Step 8: loss 0.610177\n",
      "saving model ./model/audio_100/8_20/model\n",
      "Step 9: loss 0.637092\n",
      "saving model ./model/audio_100/9_20/model\n",
      "Step 10: loss 0.59811\n",
      "saving model ./model/audio_100/10_20/model\n",
      "Step 11: loss 0.596985\n",
      "saving model ./model/audio_100/11_20/model\n",
      "Step 12: loss 0.613042\n",
      "saving model ./model/audio_100/12_20/model\n",
      "Step 13: loss 0.590328\n",
      "saving model ./model/audio_100/13_20/model\n",
      "Step 14: loss 0.554993\n",
      "saving model ./model/audio_100/14_20/model\n",
      "Step 15: loss 0.490383\n",
      "saving model ./model/audio_100/15_20/model\n",
      "Step 16: loss 0.554873\n",
      "saving model ./model/audio_100/16_20/model\n",
      "Step 17: loss 0.56587\n",
      "saving model ./model/audio_100/17_20/model\n",
      "Step 18: loss 0.458461\n",
      "saving model ./model/audio_100/18_20/model\n",
      "Step 19: loss 0.523965\n",
      "saving model ./model/audio_100/19_20/model\n",
      "Step 20: loss 0.43\n",
      "saving model ./model/audio_100/20_20/model\n",
      "loading ./model/audio_100/20_20/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_100/20_20/model\n",
      "[[0.43939427 0.5663858 ]\n",
      " [0.6855665  0.39353812]\n",
      " [0.45551136 0.51574916]\n",
      " [0.50967735 0.5104256 ]]\n",
      "[1 0 1 1]\n",
      "expected results [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name audio_201\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.732376\n",
      "saving model ./model/audio_201/1_40/model\n",
      "Step 2: loss 0.633559\n",
      "saving model ./model/audio_201/2_40/model\n",
      "Step 3: loss 0.593709\n",
      "saving model ./model/audio_201/3_40/model\n",
      "Step 4: loss 0.572072\n",
      "saving model ./model/audio_201/4_40/model\n",
      "Step 5: loss 0.68271\n",
      "saving model ./model/audio_201/5_40/model\n",
      "Step 6: loss 0.595793\n",
      "saving model ./model/audio_201/6_40/model\n",
      "Step 7: loss 0.596696\n",
      "saving model ./model/audio_201/7_40/model\n",
      "Step 8: loss 0.556086\n",
      "saving model ./model/audio_201/8_40/model\n",
      "Step 9: loss 0.637458\n",
      "saving model ./model/audio_201/9_40/model\n",
      "Step 10: loss 0.590949\n",
      "saving model ./model/audio_201/10_40/model\n",
      "Step 11: loss 0.663197\n",
      "saving model ./model/audio_201/11_40/model\n",
      "Step 12: loss 0.565656\n",
      "saving model ./model/audio_201/12_40/model\n",
      "Step 13: loss 0.570229\n",
      "saving model ./model/audio_201/13_40/model\n",
      "Step 14: loss 0.843573\n",
      "saving model ./model/audio_201/14_40/model\n",
      "Step 15: loss 0.458405\n",
      "saving model ./model/audio_201/15_40/model\n",
      "Step 16: loss 0.577334\n",
      "saving model ./model/audio_201/16_40/model\n",
      "Step 17: loss 0.624169\n",
      "saving model ./model/audio_201/17_40/model\n",
      "Step 18: loss 0.491426\n",
      "saving model ./model/audio_201/18_40/model\n",
      "Step 19: loss 0.613651\n",
      "saving model ./model/audio_201/19_40/model\n",
      "Step 20: loss 0.480963\n",
      "saving model ./model/audio_201/20_40/model\n",
      "Step 21: loss 0.426142\n",
      "saving model ./model/audio_201/21_40/model\n",
      "Step 22: loss 0.445747\n",
      "saving model ./model/audio_201/22_40/model\n",
      "Step 23: loss 0.856125\n",
      "saving model ./model/audio_201/23_40/model\n",
      "Step 24: loss 0.353715\n",
      "saving model ./model/audio_201/24_40/model\n",
      "Step 25: loss 0.703046\n",
      "saving model ./model/audio_201/25_40/model\n",
      "Step 26: loss 0.602529\n",
      "saving model ./model/audio_201/26_40/model\n",
      "Step 27: loss 0.426252\n",
      "saving model ./model/audio_201/27_40/model\n",
      "Step 28: loss 0.45402\n",
      "saving model ./model/audio_201/28_40/model\n",
      "Step 29: loss 0.530153\n",
      "saving model ./model/audio_201/29_40/model\n",
      "Step 30: loss 0.577971\n",
      "saving model ./model/audio_201/30_40/model\n",
      "Step 31: loss 0.475823\n",
      "saving model ./model/audio_201/31_40/model\n",
      "Step 32: loss 0.468161\n",
      "saving model ./model/audio_201/32_40/model\n",
      "Step 33: loss 0.540089\n",
      "saving model ./model/audio_201/33_40/model\n",
      "Step 34: loss 0.351798\n",
      "saving model ./model/audio_201/34_40/model\n",
      "Step 35: loss 0.30563\n",
      "saving model ./model/audio_201/35_40/model\n",
      "Step 36: loss 0.472183\n",
      "saving model ./model/audio_201/36_40/model\n",
      "Step 37: loss 0.336864\n",
      "saving model ./model/audio_201/37_40/model\n",
      "Step 38: loss 0.398789\n",
      "saving model ./model/audio_201/38_40/model\n",
      "Step 39: loss 0.303349\n",
      "saving model ./model/audio_201/39_40/model\n",
      "Step 40: loss 0.37132\n",
      "saving model ./model/audio_201/40_40/model\n",
      "loading ./model/audio_201/40_40/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_201/40_40/model\n",
      "[[0.4287952  0.7107146 ]\n",
      " [0.7784004  0.31745234]\n",
      " [0.8533493  0.19718693]\n",
      " [0.39970633 0.5429855 ]]\n",
      "[1 0 0 1]\n",
      "expected results [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=201, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./model/audio_201/40_40/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_201/40_40/model\n",
      "[[0.4287952  0.7107146 ]\n",
      " [0.7784004  0.31745234]\n",
      " [0.7917802  0.2827743 ]\n",
      " [0.80329025 0.26296672]\n",
      " [0.7596626  0.34796327]\n",
      " [0.8183522  0.26691192]\n",
      " [0.9127813  0.16164927]\n",
      " [0.9300833  0.13568938]\n",
      " [0.87669116 0.19700894]\n",
      " [0.90420705 0.16216436]\n",
      " [0.8533493  0.19718693]\n",
      " [0.39970633 0.5429855 ]\n",
      " [0.3739197  0.6703356 ]\n",
      " [0.179904   0.7579397 ]\n",
      " [0.28311822 0.7237356 ]\n",
      " [0.1798182  0.8356218 ]\n",
      " [0.16748893 0.7691494 ]\n",
      " [0.17559975 0.72274864]\n",
      " [0.3164792  0.6167977 ]\n",
      " [0.24945058 0.663799  ]]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "expected results None\n"
     ]
    }
   ],
   "source": [
    "(features, labels) = getLaughTracks(shuf=False, number_of_samples = 10, log=False)\n",
    "printResults(predict(getModel('%s' % ('audio_201')), 2, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name audio_500\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.739929\n",
      "saving model ./model/audio_500/1_100/model\n",
      "Step 2: loss 0.684431\n",
      "saving model ./model/audio_500/2_100/model\n",
      "Step 3: loss 0.71865\n",
      "saving model ./model/audio_500/3_100/model\n",
      "Step 4: loss 0.685007\n",
      "saving model ./model/audio_500/4_100/model\n",
      "Step 5: loss 0.673483\n",
      "saving model ./model/audio_500/5_100/model\n",
      "Step 6: loss 0.667548\n",
      "saving model ./model/audio_500/6_100/model\n",
      "Step 7: loss 0.648605\n",
      "saving model ./model/audio_500/7_100/model\n",
      "Step 8: loss 0.626448\n",
      "saving model ./model/audio_500/8_100/model\n",
      "Step 9: loss 0.665971\n",
      "saving model ./model/audio_500/9_100/model\n",
      "Step 10: loss 0.669842\n",
      "saving model ./model/audio_500/10_100/model\n",
      "Step 11: loss 0.616114\n",
      "saving model ./model/audio_500/11_100/model\n",
      "Step 12: loss 0.66934\n",
      "saving model ./model/audio_500/12_100/model\n",
      "Step 13: loss 0.632326\n",
      "saving model ./model/audio_500/13_100/model\n",
      "Step 14: loss 0.622553\n",
      "saving model ./model/audio_500/14_100/model\n",
      "Step 15: loss 0.598177\n",
      "saving model ./model/audio_500/15_100/model\n",
      "Step 16: loss 0.581654\n",
      "saving model ./model/audio_500/16_100/model\n",
      "Step 17: loss 0.604967\n",
      "saving model ./model/audio_500/17_100/model\n",
      "Step 18: loss 0.629134\n",
      "saving model ./model/audio_500/18_100/model\n",
      "Step 19: loss 0.569704\n",
      "saving model ./model/audio_500/19_100/model\n",
      "Step 20: loss 0.519417\n",
      "saving model ./model/audio_500/20_100/model\n",
      "Step 21: loss 0.553956\n",
      "saving model ./model/audio_500/21_100/model\n",
      "Step 22: loss 0.555616\n",
      "saving model ./model/audio_500/22_100/model\n",
      "Step 23: loss 0.501594\n",
      "saving model ./model/audio_500/23_100/model\n",
      "Step 24: loss 0.462942\n",
      "saving model ./model/audio_500/24_100/model\n",
      "Step 25: loss 0.467689\n",
      "saving model ./model/audio_500/25_100/model\n",
      "Step 26: loss 0.496856\n",
      "saving model ./model/audio_500/26_100/model\n",
      "Step 27: loss 0.42683\n",
      "saving model ./model/audio_500/27_100/model\n",
      "Step 28: loss 0.41765\n",
      "saving model ./model/audio_500/28_100/model\n",
      "Step 29: loss 0.46038\n",
      "saving model ./model/audio_500/29_100/model\n",
      "Step 30: loss 0.413742\n",
      "saving model ./model/audio_500/30_100/model\n",
      "Step 31: loss 0.456059\n",
      "saving model ./model/audio_500/31_100/model\n",
      "Step 32: loss 0.364364\n",
      "saving model ./model/audio_500/32_100/model\n",
      "Step 35: loss 0.513915\n",
      "saving model ./model/audio_500/35_100/model\n",
      "Step 36: loss 0.331815\n",
      "saving model ./model/audio_500/36_100/model\n",
      "Step 37: loss 0.39002\n",
      "saving model ./model/audio_500/37_100/model\n",
      "Step 38: loss 0.23196\n",
      "saving model ./model/audio_500/38_100/model\n",
      "Step 39: loss 0.337465\n",
      "saving model ./model/audio_500/39_100/model\n",
      "Step 40: loss 0.304142\n",
      "saving model ./model/audio_500/40_100/model\n",
      "Step 41: loss 0.270712\n",
      "saving model ./model/audio_500/41_100/model\n",
      "Step 42: loss 0.377078\n",
      "saving model ./model/audio_500/42_100/model\n",
      "Step 43: loss 0.369832\n",
      "saving model ./model/audio_500/43_100/model\n",
      "Step 44: loss 0.185506\n",
      "saving model ./model/audio_500/44_100/model\n",
      "Step 45: loss 0.458822\n",
      "saving model ./model/audio_500/45_100/model\n",
      "Step 46: loss 0.278891\n",
      "saving model ./model/audio_500/46_100/model\n",
      "Step 47: loss 0.296877\n",
      "saving model ./model/audio_500/47_100/model\n",
      "Step 48: loss 0.169948\n",
      "saving model ./model/audio_500/48_100/model\n",
      "Step 49: loss 0.25802\n",
      "saving model ./model/audio_500/49_100/model\n",
      "Step 50: loss 0.161407\n",
      "saving model ./model/audio_500/50_100/model\n",
      "Step 51: loss 0.167713\n",
      "saving model ./model/audio_500/51_100/model\n",
      "Step 52: loss 0.249816\n",
      "saving model ./model/audio_500/52_100/model\n",
      "Step 53: loss 0.283789\n",
      "saving model ./model/audio_500/53_100/model\n",
      "Step 54: loss 0.140381\n",
      "saving model ./model/audio_500/54_100/model\n",
      "Step 55: loss 0.239915\n",
      "saving model ./model/audio_500/55_100/model\n",
      "Step 56: loss 0.238081\n",
      "saving model ./model/audio_500/56_100/model\n",
      "Step 57: loss 0.275478\n",
      "saving model ./model/audio_500/57_100/model\n",
      "Step 58: loss 0.165552\n",
      "saving model ./model/audio_500/58_100/model\n",
      "Step 59: loss 0.286273\n",
      "saving model ./model/audio_500/59_100/model\n",
      "Step 60: loss 0.171712\n",
      "saving model ./model/audio_500/60_100/model\n",
      "Step 61: loss 0.377915\n",
      "saving model ./model/audio_500/61_100/model\n",
      "Step 62: loss 0.206507\n",
      "saving model ./model/audio_500/62_100/model\n",
      "Step 63: loss 0.396353\n",
      "saving model ./model/audio_500/63_100/model\n",
      "Step 64: loss 0.282371\n",
      "saving model ./model/audio_500/64_100/model\n",
      "Step 65: loss 0.185656\n",
      "saving model ./model/audio_500/65_100/model\n",
      "Step 66: loss 0.402201\n",
      "saving model ./model/audio_500/66_100/model\n",
      "Step 67: loss 0.156321\n",
      "saving model ./model/audio_500/67_100/model\n",
      "Step 70: loss 0.324656\n",
      "saving model ./model/audio_500/70_100/model\n",
      "Step 71: loss 0.282714\n",
      "saving model ./model/audio_500/71_100/model\n",
      "Step 72: loss 0.141446\n",
      "saving model ./model/audio_500/72_100/model\n",
      "Step 73: loss 0.231347\n",
      "saving model ./model/audio_500/73_100/model\n",
      "Step 74: loss 0.229958\n",
      "saving model ./model/audio_500/74_100/model\n",
      "Step 75: loss 0.185397\n",
      "saving model ./model/audio_500/75_100/model\n",
      "Step 76: loss 0.152162\n",
      "saving model ./model/audio_500/76_100/model\n",
      "Step 77: loss 0.21524\n",
      "saving model ./model/audio_500/77_100/model\n",
      "Step 78: loss 0.183736\n",
      "saving model ./model/audio_500/78_100/model\n",
      "Step 79: loss 0.164091\n",
      "saving model ./model/audio_500/79_100/model\n",
      "Step 80: loss 0.126215\n",
      "saving model ./model/audio_500/80_100/model\n",
      "Step 81: loss 0.277421\n",
      "saving model ./model/audio_500/81_100/model\n",
      "Step 82: loss 0.262904\n",
      "saving model ./model/audio_500/82_100/model\n",
      "Step 83: loss 0.217872\n",
      "saving model ./model/audio_500/83_100/model\n",
      "Step 84: loss 0.216492\n",
      "saving model ./model/audio_500/84_100/model\n",
      "Step 85: loss 0.0899169\n",
      "saving model ./model/audio_500/85_100/model\n",
      "Step 86: loss 0.185375\n",
      "saving model ./model/audio_500/86_100/model\n",
      "Step 87: loss 0.154688\n",
      "saving model ./model/audio_500/87_100/model\n",
      "Step 88: loss 0.355335\n",
      "saving model ./model/audio_500/88_100/model\n",
      "Step 89: loss 0.180054\n",
      "saving model ./model/audio_500/89_100/model\n",
      "Step 90: loss 0.0844739\n",
      "saving model ./model/audio_500/90_100/model\n",
      "Step 91: loss 0.193111\n",
      "saving model ./model/audio_500/91_100/model\n",
      "Step 92: loss 0.136326\n",
      "saving model ./model/audio_500/92_100/model\n",
      "Step 93: loss 0.222471\n",
      "saving model ./model/audio_500/93_100/model\n",
      "Step 94: loss 0.208546\n",
      "saving model ./model/audio_500/94_100/model\n",
      "Step 95: loss 0.132532\n",
      "saving model ./model/audio_500/95_100/model\n",
      "Step 96: loss 0.197298\n",
      "saving model ./model/audio_500/96_100/model\n",
      "Step 97: loss 0.118765\n",
      "saving model ./model/audio_500/97_100/model\n",
      "Step 98: loss 0.0953397\n",
      "saving model ./model/audio_500/98_100/model\n",
      "Step 99: loss 0.137056\n",
      "saving model ./model/audio_500/99_100/model\n",
      "Step 100: loss 0.11439\n",
      "saving model ./model/audio_500/100_100/model\n",
      "loading ./model/audio_500/100_100/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_500/100_100/model\n",
      "[[0.24273477 0.7191201 ]\n",
      " [0.71170944 0.2742053 ]\n",
      " [0.9467495  0.04360906]\n",
      " [0.352737   0.5867095 ]]\n",
      "[1 0 0 1]\n",
      "expected results [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=500, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name audio_600\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.717405\n",
      "saving model ./model/audio_600/1_300/model\n",
      "Step 2: loss 0.694363\n",
      "saving model ./model/audio_600/2_300/model\n",
      "Step 3: loss 0.670209\n",
      "saving model ./model/audio_600/3_300/model\n",
      "Step 4: loss 0.65375\n",
      "saving model ./model/audio_600/4_300/model\n",
      "Step 5: loss 0.656008\n",
      "saving model ./model/audio_600/5_300/model\n",
      "Step 6: loss 0.63023\n",
      "saving model ./model/audio_600/6_300/model\n",
      "Step 7: loss 0.638339\n",
      "saving model ./model/audio_600/7_300/model\n",
      "Step 8: loss 0.653481\n",
      "saving model ./model/audio_600/8_300/model\n",
      "Step 9: loss 0.603731\n",
      "saving model ./model/audio_600/9_300/model\n",
      "Step 10: loss 0.609336\n",
      "saving model ./model/audio_600/10_300/model\n",
      "Step 11: loss 0.608169\n",
      "saving model ./model/audio_600/11_300/model\n",
      "Step 12: loss 0.664959\n",
      "saving model ./model/audio_600/12_300/model\n",
      "Step 13: loss 0.60818\n",
      "saving model ./model/audio_600/13_300/model\n",
      "Step 14: loss 0.560694\n",
      "saving model ./model/audio_600/14_300/model\n",
      "Step 15: loss 0.566482\n",
      "saving model ./model/audio_600/15_300/model\n",
      "Step 16: loss 0.507735\n",
      "saving model ./model/audio_600/16_300/model\n",
      "Step 17: loss 0.574478\n",
      "saving model ./model/audio_600/17_300/model\n",
      "Step 18: loss 0.557711\n",
      "saving model ./model/audio_600/18_300/model\n",
      "Step 19: loss 0.480275\n",
      "saving model ./model/audio_600/19_300/model\n",
      "Step 20: loss 0.54496\n",
      "saving model ./model/audio_600/20_300/model\n",
      "Step 21: loss 0.555989\n",
      "saving model ./model/audio_600/21_300/model\n",
      "Step 22: loss 0.62477\n",
      "saving model ./model/audio_600/22_300/model\n",
      "Step 23: loss 0.498126\n",
      "saving model ./model/audio_600/23_300/model\n",
      "Step 24: loss 0.576271\n",
      "saving model ./model/audio_600/24_300/model\n",
      "Step 25: loss 0.452096\n",
      "saving model ./model/audio_600/25_300/model\n",
      "Step 26: loss 0.425299\n",
      "saving model ./model/audio_600/26_300/model\n",
      "Step 27: loss 0.458502\n",
      "saving model ./model/audio_600/27_300/model\n",
      "Step 28: loss 0.491482\n",
      "saving model ./model/audio_600/28_300/model\n",
      "Step 29: loss 0.452222\n",
      "saving model ./model/audio_600/29_300/model\n",
      "Step 30: loss 0.315352\n",
      "saving model ./model/audio_600/30_300/model\n",
      "Step 31: loss 0.377015\n",
      "saving model ./model/audio_600/31_300/model\n",
      "Step 32: loss 0.483065\n",
      "saving model ./model/audio_600/32_300/model\n",
      "Step 33: loss 0.449634\n",
      "saving model ./model/audio_600/33_300/model\n",
      "Step 34: loss 0.42803\n",
      "saving model ./model/audio_600/34_300/model\n",
      "Step 35: loss 0.390694\n",
      "saving model ./model/audio_600/35_300/model\n",
      "Step 36: loss 0.42854\n",
      "saving model ./model/audio_600/36_300/model\n",
      "Step 37: loss 0.408265\n",
      "saving model ./model/audio_600/37_300/model\n",
      "Step 38: loss 0.297168\n",
      "saving model ./model/audio_600/38_300/model\n",
      "Step 39: loss 0.300472\n",
      "saving model ./model/audio_600/39_300/model\n",
      "Step 40: loss 0.280045\n",
      "saving model ./model/audio_600/40_300/model\n",
      "Step 41: loss 0.215552\n",
      "saving model ./model/audio_600/41_300/model\n",
      "Step 42: loss 0.364891\n",
      "saving model ./model/audio_600/42_300/model\n",
      "Step 43: loss 0.246585\n",
      "saving model ./model/audio_600/43_300/model\n",
      "Step 44: loss 0.238375\n",
      "saving model ./model/audio_600/44_300/model\n",
      "Step 45: loss 0.189078\n",
      "saving model ./model/audio_600/45_300/model\n",
      "Step 46: loss 0.374244\n",
      "saving model ./model/audio_600/46_300/model\n",
      "Step 47: loss 0.398804\n",
      "saving model ./model/audio_600/47_300/model\n",
      "Step 48: loss 0.363254\n",
      "saving model ./model/audio_600/48_300/model\n",
      "Step 49: loss 0.244593\n",
      "saving model ./model/audio_600/49_300/model\n",
      "Step 50: loss 0.299855\n",
      "saving model ./model/audio_600/50_300/model\n",
      "Step 51: loss 0.259738\n",
      "saving model ./model/audio_600/51_300/model\n",
      "Step 52: loss 0.330319\n",
      "saving model ./model/audio_600/52_300/model\n",
      "Step 53: loss 0.292898\n",
      "saving model ./model/audio_600/53_300/model\n",
      "Step 54: loss 0.225592\n",
      "saving model ./model/audio_600/54_300/model\n",
      "Step 55: loss 0.387464\n",
      "saving model ./model/audio_600/55_300/model\n",
      "Step 56: loss 0.261469\n",
      "saving model ./model/audio_600/56_300/model\n",
      "Step 57: loss 0.411371\n",
      "saving model ./model/audio_600/57_300/model\n",
      "Step 58: loss 0.352029\n",
      "saving model ./model/audio_600/58_300/model\n",
      "Step 59: loss 0.266025\n",
      "saving model ./model/audio_600/59_300/model\n",
      "Step 60: loss 0.472525\n",
      "saving model ./model/audio_600/60_300/model\n",
      "Step 61: loss 0.255255\n",
      "saving model ./model/audio_600/61_300/model\n",
      "Step 62: loss 0.204524\n",
      "saving model ./model/audio_600/62_300/model\n",
      "Step 63: loss 0.311122\n",
      "saving model ./model/audio_600/63_300/model\n",
      "Step 64: loss 0.201852\n",
      "saving model ./model/audio_600/64_300/model\n",
      "Step 65: loss 0.253905\n",
      "saving model ./model/audio_600/65_300/model\n",
      "Step 66: loss 0.162886\n",
      "saving model ./model/audio_600/66_300/model\n",
      "Step 67: loss 0.213639\n",
      "saving model ./model/audio_600/67_300/model\n",
      "Step 68: loss 0.224769\n",
      "saving model ./model/audio_600/68_300/model\n",
      "Step 69: loss 0.263448\n",
      "saving model ./model/audio_600/69_300/model\n",
      "Step 70: loss 0.239226\n",
      "saving model ./model/audio_600/70_300/model\n",
      "Step 71: loss 0.145725\n",
      "saving model ./model/audio_600/71_300/model\n",
      "Step 72: loss 0.22061\n",
      "saving model ./model/audio_600/72_300/model\n",
      "Step 73: loss 0.289153\n",
      "saving model ./model/audio_600/73_300/model\n",
      "Step 74: loss 0.131113\n",
      "saving model ./model/audio_600/74_300/model\n",
      "Step 75: loss 0.301585\n",
      "saving model ./model/audio_600/75_300/model\n",
      "Step 76: loss 0.238886\n",
      "saving model ./model/audio_600/76_300/model\n",
      "Step 77: loss 0.267179\n",
      "saving model ./model/audio_600/77_300/model\n",
      "Step 78: loss 0.230026\n",
      "saving model ./model/audio_600/78_300/model\n",
      "Step 79: loss 0.175163\n",
      "saving model ./model/audio_600/79_300/model\n",
      "Step 80: loss 0.300306\n",
      "saving model ./model/audio_600/80_300/model\n",
      "Step 81: loss 0.26326\n",
      "saving model ./model/audio_600/81_300/model\n",
      "Step 82: loss 0.148643\n",
      "saving model ./model/audio_600/82_300/model\n",
      "Step 83: loss 0.13616\n",
      "saving model ./model/audio_600/83_300/model\n",
      "Step 84: loss 0.355912\n",
      "saving model ./model/audio_600/84_300/model\n",
      "Step 85: loss 0.231912\n",
      "saving model ./model/audio_600/85_300/model\n",
      "Step 86: loss 0.186838\n",
      "saving model ./model/audio_600/86_300/model\n",
      "Step 87: loss 0.163627\n",
      "saving model ./model/audio_600/87_300/model\n",
      "Step 88: loss 0.275827\n",
      "saving model ./model/audio_600/88_300/model\n",
      "Step 89: loss 0.252877\n",
      "saving model ./model/audio_600/89_300/model\n",
      "Step 90: loss 0.376161\n",
      "saving model ./model/audio_600/90_300/model\n",
      "Step 91: loss 0.340683\n",
      "saving model ./model/audio_600/91_300/model\n",
      "Step 92: loss 0.230652\n",
      "saving model ./model/audio_600/92_300/model\n",
      "Step 93: loss 0.189253\n",
      "saving model ./model/audio_600/93_300/model\n",
      "Step 94: loss 0.280584\n",
      "saving model ./model/audio_600/94_300/model\n",
      "Step 95: loss 0.162665\n",
      "saving model ./model/audio_600/95_300/model\n",
      "Step 96: loss 0.223828\n",
      "saving model ./model/audio_600/96_300/model\n",
      "Step 97: loss 0.301134\n",
      "saving model ./model/audio_600/97_300/model\n",
      "Step 98: loss 0.127055\n",
      "saving model ./model/audio_600/98_300/model\n",
      "Step 99: loss 0.160357\n",
      "saving model ./model/audio_600/99_300/model\n",
      "Step 100: loss 0.248139\n",
      "saving model ./model/audio_600/100_300/model\n",
      "Step 101: loss 0.17816\n",
      "saving model ./model/audio_600/101_300/model\n",
      "Step 102: loss 0.190087\n",
      "saving model ./model/audio_600/102_300/model\n",
      "Step 103: loss 0.301228\n",
      "saving model ./model/audio_600/103_300/model\n",
      "Step 104: loss 0.21373\n",
      "saving model ./model/audio_600/104_300/model\n",
      "Step 105: loss 0.330036\n",
      "saving model ./model/audio_600/105_300/model\n",
      "Step 106: loss 0.194026\n",
      "saving model ./model/audio_600/106_300/model\n",
      "Step 107: loss 0.131817\n",
      "saving model ./model/audio_600/107_300/model\n",
      "Step 108: loss 0.205794\n",
      "saving model ./model/audio_600/108_300/model\n",
      "Step 109: loss 0.246163\n",
      "saving model ./model/audio_600/109_300/model\n",
      "Step 110: loss 0.208734\n",
      "saving model ./model/audio_600/110_300/model\n",
      "Step 111: loss 0.191532\n",
      "saving model ./model/audio_600/111_300/model\n",
      "Step 112: loss 0.184076\n",
      "saving model ./model/audio_600/112_300/model\n",
      "Step 113: loss 0.233142\n",
      "saving model ./model/audio_600/113_300/model\n",
      "Step 114: loss 0.217969\n",
      "saving model ./model/audio_600/114_300/model\n",
      "Step 115: loss 0.366122\n",
      "saving model ./model/audio_600/115_300/model\n",
      "Step 116: loss 0.125975\n",
      "saving model ./model/audio_600/116_300/model\n",
      "Step 117: loss 0.225176\n",
      "saving model ./model/audio_600/117_300/model\n",
      "Step 118: loss 0.194775\n",
      "saving model ./model/audio_600/118_300/model\n",
      "Step 119: loss 0.184514\n",
      "saving model ./model/audio_600/119_300/model\n",
      "Step 120: loss 0.283607\n",
      "saving model ./model/audio_600/120_300/model\n",
      "Step 121: loss 0.250522\n",
      "saving model ./model/audio_600/121_300/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 122: loss 0.286293\n",
      "saving model ./model/audio_600/122_300/model\n",
      "Step 123: loss 0.207651\n",
      "saving model ./model/audio_600/123_300/model\n",
      "Step 124: loss 0.146712\n",
      "saving model ./model/audio_600/124_300/model\n",
      "Step 125: loss 0.20582\n",
      "saving model ./model/audio_600/125_300/model\n",
      "Step 126: loss 0.180919\n",
      "saving model ./model/audio_600/126_300/model\n",
      "Step 127: loss 0.134022\n",
      "saving model ./model/audio_600/127_300/model\n",
      "Step 128: loss 0.290647\n",
      "saving model ./model/audio_600/128_300/model\n",
      "Step 129: loss 0.277411\n",
      "saving model ./model/audio_600/129_300/model\n",
      "Step 130: loss 0.175952\n",
      "saving model ./model/audio_600/130_300/model\n",
      "Step 131: loss 0.214518\n",
      "saving model ./model/audio_600/131_300/model\n",
      "Step 132: loss 0.181963\n",
      "saving model ./model/audio_600/132_300/model\n",
      "Step 133: loss 0.175504\n",
      "saving model ./model/audio_600/133_300/model\n",
      "Step 134: loss 0.216229\n",
      "saving model ./model/audio_600/134_300/model\n",
      "Step 135: loss 0.124865\n",
      "saving model ./model/audio_600/135_300/model\n",
      "Step 136: loss 0.329814\n",
      "saving model ./model/audio_600/136_300/model\n",
      "Step 137: loss 0.14968\n",
      "saving model ./model/audio_600/137_300/model\n",
      "Step 138: loss 0.205556\n",
      "saving model ./model/audio_600/138_300/model\n",
      "Step 139: loss 0.208604\n",
      "saving model ./model/audio_600/139_300/model\n",
      "Step 140: loss 0.140815\n",
      "saving model ./model/audio_600/140_300/model\n",
      "Step 141: loss 0.125415\n",
      "saving model ./model/audio_600/141_300/model\n",
      "Step 142: loss 0.382849\n",
      "saving model ./model/audio_600/142_300/model\n",
      "Step 143: loss 0.0751165\n",
      "saving model ./model/audio_600/143_300/model\n",
      "Step 144: loss 0.195242\n",
      "saving model ./model/audio_600/144_300/model\n",
      "Step 145: loss 0.198213\n",
      "saving model ./model/audio_600/145_300/model\n",
      "Step 146: loss 0.148039\n",
      "saving model ./model/audio_600/146_300/model\n",
      "Step 147: loss 0.135035\n",
      "saving model ./model/audio_600/147_300/model\n",
      "Step 148: loss 0.238875\n",
      "saving model ./model/audio_600/148_300/model\n",
      "Step 149: loss 0.130252\n",
      "saving model ./model/audio_600/149_300/model\n",
      "Step 150: loss 0.253434\n",
      "saving model ./model/audio_600/150_300/model\n",
      "Step 151: loss 0.18835\n",
      "saving model ./model/audio_600/151_300/model\n",
      "Step 152: loss 0.228805\n",
      "saving model ./model/audio_600/152_300/model\n",
      "Step 153: loss 0.294409\n",
      "saving model ./model/audio_600/153_300/model\n",
      "Step 154: loss 0.271614\n",
      "saving model ./model/audio_600/154_300/model\n",
      "Step 155: loss 0.146508\n",
      "saving model ./model/audio_600/155_300/model\n",
      "Step 156: loss 0.153309\n",
      "saving model ./model/audio_600/156_300/model\n",
      "Step 157: loss 0.193667\n",
      "saving model ./model/audio_600/157_300/model\n",
      "Step 158: loss 0.332176\n",
      "saving model ./model/audio_600/158_300/model\n",
      "Step 159: loss 0.13741\n",
      "saving model ./model/audio_600/159_300/model\n",
      "Step 160: loss 0.120808\n",
      "saving model ./model/audio_600/160_300/model\n",
      "Step 161: loss 0.173514\n",
      "saving model ./model/audio_600/161_300/model\n",
      "Step 162: loss 0.171542\n",
      "saving model ./model/audio_600/162_300/model\n",
      "Step 163: loss 0.197441\n",
      "saving model ./model/audio_600/163_300/model\n",
      "Step 164: loss 0.176846\n",
      "saving model ./model/audio_600/164_300/model\n",
      "Step 165: loss 0.200423\n",
      "saving model ./model/audio_600/165_300/model\n",
      "Step 166: loss 0.211501\n",
      "saving model ./model/audio_600/166_300/model\n",
      "Step 167: loss 0.160428\n",
      "saving model ./model/audio_600/167_300/model\n",
      "Step 168: loss 0.190067\n",
      "saving model ./model/audio_600/168_300/model\n",
      "Step 169: loss 0.336843\n",
      "saving model ./model/audio_600/169_300/model\n",
      "Step 170: loss 0.252875\n",
      "saving model ./model/audio_600/170_300/model\n",
      "Step 171: loss 0.156523\n",
      "saving model ./model/audio_600/171_300/model\n",
      "Step 172: loss 0.138055\n",
      "saving model ./model/audio_600/172_300/model\n",
      "Step 173: loss 0.1504\n",
      "saving model ./model/audio_600/173_300/model\n",
      "Step 174: loss 0.160646\n",
      "saving model ./model/audio_600/174_300/model\n",
      "Step 175: loss 0.0830711\n",
      "saving model ./model/audio_600/175_300/model\n",
      "Step 176: loss 0.296529\n",
      "saving model ./model/audio_600/176_300/model\n",
      "Step 177: loss 0.141024\n",
      "saving model ./model/audio_600/177_300/model\n",
      "Step 178: loss 0.169071\n",
      "saving model ./model/audio_600/178_300/model\n",
      "Step 179: loss 0.134114\n",
      "saving model ./model/audio_600/179_300/model\n",
      "Step 180: loss 0.13531\n",
      "saving model ./model/audio_600/180_300/model\n",
      "Step 181: loss 0.168637\n",
      "saving model ./model/audio_600/181_300/model\n",
      "Step 182: loss 0.220787\n",
      "saving model ./model/audio_600/182_300/model\n",
      "Step 183: loss 0.172138\n",
      "saving model ./model/audio_600/183_300/model\n",
      "Step 184: loss 0.195107\n",
      "saving model ./model/audio_600/184_300/model\n",
      "Step 185: loss 0.296106\n",
      "saving model ./model/audio_600/185_300/model\n",
      "Step 186: loss 0.164941\n",
      "saving model ./model/audio_600/186_300/model\n",
      "Step 187: loss 0.200971\n",
      "saving model ./model/audio_600/187_300/model\n",
      "Step 188: loss 0.246465\n",
      "saving model ./model/audio_600/188_300/model\n",
      "Step 189: loss 0.254201\n",
      "saving model ./model/audio_600/189_300/model\n",
      "Step 190: loss 0.153819\n",
      "saving model ./model/audio_600/190_300/model\n",
      "Step 191: loss 0.20608\n",
      "saving model ./model/audio_600/191_300/model\n",
      "Step 192: loss 0.152093\n",
      "saving model ./model/audio_600/192_300/model\n",
      "Step 193: loss 0.197015\n",
      "saving model ./model/audio_600/193_300/model\n",
      "Step 194: loss 0.181369\n",
      "saving model ./model/audio_600/194_300/model\n",
      "Step 195: loss 0.0950043\n",
      "saving model ./model/audio_600/195_300/model\n",
      "Step 196: loss 0.0828316\n",
      "saving model ./model/audio_600/196_300/model\n",
      "Step 197: loss 0.23008\n",
      "saving model ./model/audio_600/197_300/model\n",
      "Step 198: loss 0.12871\n",
      "saving model ./model/audio_600/198_300/model\n",
      "Step 199: loss 0.180575\n",
      "saving model ./model/audio_600/199_300/model\n",
      "Step 200: loss 0.196926\n",
      "saving model ./model/audio_600/200_300/model\n",
      "Step 201: loss 0.168639\n",
      "saving model ./model/audio_600/201_300/model\n",
      "Step 202: loss 0.126724\n",
      "saving model ./model/audio_600/202_300/model\n",
      "Step 203: loss 0.128206\n",
      "saving model ./model/audio_600/203_300/model\n",
      "Step 204: loss 0.190089\n",
      "saving model ./model/audio_600/204_300/model\n",
      "Step 205: loss 0.244568\n",
      "saving model ./model/audio_600/205_300/model\n",
      "Step 206: loss 0.117722\n",
      "saving model ./model/audio_600/206_300/model\n",
      "Step 207: loss 0.0661612\n",
      "saving model ./model/audio_600/207_300/model\n",
      "Step 208: loss 0.101874\n",
      "saving model ./model/audio_600/208_300/model\n",
      "Step 209: loss 0.135536\n",
      "saving model ./model/audio_600/209_300/model\n",
      "Step 210: loss 0.31299\n",
      "saving model ./model/audio_600/210_300/model\n",
      "Step 211: loss 0.108601\n",
      "saving model ./model/audio_600/211_300/model\n",
      "Step 212: loss 0.18676\n",
      "saving model ./model/audio_600/212_300/model\n",
      "Step 213: loss 0.165703\n",
      "saving model ./model/audio_600/213_300/model\n",
      "Step 214: loss 0.119293\n",
      "saving model ./model/audio_600/214_300/model\n",
      "Step 215: loss 0.313851\n",
      "saving model ./model/audio_600/215_300/model\n",
      "Step 216: loss 0.073332\n",
      "saving model ./model/audio_600/216_300/model\n",
      "Step 217: loss 0.158471\n",
      "saving model ./model/audio_600/217_300/model\n",
      "Step 218: loss 0.197452\n",
      "saving model ./model/audio_600/218_300/model\n",
      "Step 219: loss 0.10925\n",
      "saving model ./model/audio_600/219_300/model\n",
      "Step 220: loss 0.122416\n",
      "saving model ./model/audio_600/220_300/model\n",
      "Step 221: loss 0.122769\n",
      "saving model ./model/audio_600/221_300/model\n",
      "Step 222: loss 0.110998\n",
      "saving model ./model/audio_600/222_300/model\n",
      "Step 223: loss 0.15191\n",
      "saving model ./model/audio_600/223_300/model\n",
      "Step 224: loss 0.216899\n",
      "saving model ./model/audio_600/224_300/model\n",
      "Step 225: loss 0.140999\n",
      "saving model ./model/audio_600/225_300/model\n",
      "Step 226: loss 0.064056\n",
      "saving model ./model/audio_600/226_300/model\n",
      "Step 227: loss 0.267575\n",
      "saving model ./model/audio_600/227_300/model\n",
      "Step 228: loss 0.0843715\n",
      "saving model ./model/audio_600/228_300/model\n",
      "Step 229: loss 0.112635\n",
      "saving model ./model/audio_600/229_300/model\n",
      "Step 230: loss 0.112599\n",
      "saving model ./model/audio_600/230_300/model\n",
      "Step 231: loss 0.107394\n",
      "saving model ./model/audio_600/231_300/model\n",
      "Step 232: loss 0.129189\n",
      "saving model ./model/audio_600/232_300/model\n",
      "Step 233: loss 0.18528\n",
      "saving model ./model/audio_600/233_300/model\n",
      "Step 234: loss 0.160601\n",
      "saving model ./model/audio_600/234_300/model\n",
      "Step 235: loss 0.271217\n",
      "saving model ./model/audio_600/235_300/model\n",
      "Step 236: loss 0.0963344\n",
      "saving model ./model/audio_600/236_300/model\n",
      "Step 237: loss 0.110495\n",
      "saving model ./model/audio_600/237_300/model\n",
      "Step 238: loss 0.134432\n",
      "saving model ./model/audio_600/238_300/model\n",
      "Step 239: loss 0.153313\n",
      "saving model ./model/audio_600/239_300/model\n",
      "Step 240: loss 0.224606\n",
      "saving model ./model/audio_600/240_300/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 241: loss 0.169814\n",
      "saving model ./model/audio_600/241_300/model\n",
      "Step 242: loss 0.120375\n",
      "saving model ./model/audio_600/242_300/model\n",
      "Step 243: loss 0.146614\n",
      "saving model ./model/audio_600/243_300/model\n",
      "Step 244: loss 0.169205\n",
      "saving model ./model/audio_600/244_300/model\n",
      "Step 245: loss 0.194513\n",
      "saving model ./model/audio_600/245_300/model\n",
      "Step 246: loss 0.16926\n",
      "saving model ./model/audio_600/246_300/model\n",
      "Step 247: loss 0.124347\n",
      "saving model ./model/audio_600/247_300/model\n",
      "Step 248: loss 0.204761\n",
      "saving model ./model/audio_600/248_300/model\n",
      "Step 249: loss 0.0950304\n",
      "saving model ./model/audio_600/249_300/model\n",
      "Step 250: loss 0.129634\n",
      "saving model ./model/audio_600/250_300/model\n",
      "Step 251: loss 0.0899939\n",
      "saving model ./model/audio_600/251_300/model\n",
      "Step 252: loss 0.181625\n",
      "saving model ./model/audio_600/252_300/model\n",
      "Step 253: loss 0.105643\n",
      "saving model ./model/audio_600/253_300/model\n",
      "Step 254: loss 0.233315\n",
      "saving model ./model/audio_600/254_300/model\n",
      "Step 255: loss 0.139201\n",
      "saving model ./model/audio_600/255_300/model\n",
      "Step 256: loss 0.200175\n",
      "saving model ./model/audio_600/256_300/model\n",
      "Step 257: loss 0.0801707\n",
      "saving model ./model/audio_600/257_300/model\n",
      "Step 258: loss 0.169023\n",
      "saving model ./model/audio_600/258_300/model\n",
      "Step 259: loss 0.143699\n",
      "saving model ./model/audio_600/259_300/model\n",
      "Step 260: loss 0.0883241\n",
      "saving model ./model/audio_600/260_300/model\n",
      "Step 261: loss 0.10064\n",
      "saving model ./model/audio_600/261_300/model\n",
      "Step 262: loss 0.136019\n",
      "saving model ./model/audio_600/262_300/model\n",
      "Step 263: loss 0.252903\n",
      "saving model ./model/audio_600/263_300/model\n",
      "Step 264: loss 0.171472\n",
      "saving model ./model/audio_600/264_300/model\n",
      "Step 265: loss 0.156634\n",
      "saving model ./model/audio_600/265_300/model\n",
      "Step 266: loss 0.0616215\n",
      "saving model ./model/audio_600/266_300/model\n",
      "Step 267: loss 0.105878\n",
      "saving model ./model/audio_600/267_300/model\n",
      "Step 268: loss 0.147079\n",
      "saving model ./model/audio_600/268_300/model\n",
      "Step 269: loss 0.0628273\n",
      "saving model ./model/audio_600/269_300/model\n",
      "Step 270: loss 0.176463\n",
      "saving model ./model/audio_600/270_300/model\n",
      "Step 271: loss 0.197481\n",
      "saving model ./model/audio_600/271_300/model\n",
      "Step 272: loss 0.105515\n",
      "saving model ./model/audio_600/272_300/model\n",
      "Step 273: loss 0.155013\n",
      "saving model ./model/audio_600/273_300/model\n",
      "Step 274: loss 0.0975495\n",
      "saving model ./model/audio_600/274_300/model\n",
      "Step 275: loss 0.152814\n",
      "saving model ./model/audio_600/275_300/model\n",
      "Step 276: loss 0.104296\n",
      "saving model ./model/audio_600/276_300/model\n",
      "Step 277: loss 0.125415\n",
      "saving model ./model/audio_600/277_300/model\n",
      "Step 278: loss 0.176998\n",
      "saving model ./model/audio_600/278_300/model\n",
      "Step 279: loss 0.198282\n",
      "saving model ./model/audio_600/279_300/model\n",
      "Step 280: loss 0.0733592\n",
      "saving model ./model/audio_600/280_300/model\n",
      "Step 281: loss 0.0981745\n",
      "saving model ./model/audio_600/281_300/model\n",
      "Step 282: loss 0.0843394\n",
      "saving model ./model/audio_600/282_300/model\n",
      "Step 283: loss 0.0705153\n",
      "saving model ./model/audio_600/283_300/model\n",
      "Step 284: loss 0.387091\n",
      "saving model ./model/audio_600/284_300/model\n",
      "Step 285: loss 0.126599\n",
      "saving model ./model/audio_600/285_300/model\n",
      "Step 286: loss 0.140591\n",
      "saving model ./model/audio_600/286_300/model\n",
      "Step 287: loss 0.169232\n",
      "saving model ./model/audio_600/287_300/model\n",
      "Step 288: loss 0.370872\n",
      "saving model ./model/audio_600/288_300/model\n",
      "Step 289: loss 0.102147\n",
      "saving model ./model/audio_600/289_300/model\n",
      "Step 290: loss 0.278652\n",
      "saving model ./model/audio_600/290_300/model\n",
      "Step 291: loss 0.136748\n",
      "saving model ./model/audio_600/291_300/model\n",
      "Step 292: loss 0.219892\n",
      "saving model ./model/audio_600/292_300/model\n",
      "Step 293: loss 0.13694\n",
      "saving model ./model/audio_600/293_300/model\n",
      "Step 294: loss 0.0919917\n",
      "saving model ./model/audio_600/294_300/model\n",
      "Step 295: loss 0.202514\n",
      "saving model ./model/audio_600/295_300/model\n",
      "Step 296: loss 0.388819\n",
      "saving model ./model/audio_600/296_300/model\n",
      "Step 297: loss 0.151349\n",
      "saving model ./model/audio_600/297_300/model\n",
      "Step 298: loss 0.213178\n",
      "saving model ./model/audio_600/298_300/model\n",
      "Step 299: loss 0.19744\n",
      "saving model ./model/audio_600/299_300/model\n",
      "Step 300: loss 0.0992803\n",
      "saving model ./model/audio_600/300_300/model\n",
      "loading ./model/audio_600/300_300/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_600/300_300/model\n",
      "[[0.93022645 0.04779049]\n",
      " [0.9882008  0.01123085]\n",
      " [0.8071062  0.1965018 ]\n",
      " [0.649517   0.34406373]]\n",
      "[0 0 0 0]\n",
      "expected results [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=600, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./model/audio_600/300_300/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_600/300_300/model\n",
      "[[0.93022645 0.04779049]\n",
      " [0.9882008  0.01123085]\n",
      " [0.99851245 0.00118623]\n",
      " [0.9982622  0.00138261]\n",
      " [0.8071062  0.1965018 ]\n",
      " [0.649517   0.34406373]\n",
      " [0.13383405 0.8822048 ]\n",
      " [0.21634802 0.8144273 ]]\n",
      "[0 0 0 0 0 0 1 1]\n",
      "expected results [0, 0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "(features, labels) = getLaughTracks(shuf=False, number_of_samples = 4, log=False)\n",
    "preds = predict(getModel('%s' % ('audio_600')), 2, features)\n",
    "printResults(preds, [0, 0, 0, 0, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./model/audio_2000/7/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_2000/7/model\n",
      "[[0.46733063 0.72856736]\n",
      " [0.5200044  0.58841306]\n",
      " [0.5308451  0.5193135 ]\n",
      " [0.5482788  0.53807145]\n",
      " [0.48719636 0.55772114]\n",
      " [0.47477028 0.7101242 ]\n",
      " [0.46824598 0.74748474]\n",
      " [0.47193593 0.71191275]]\n",
      "[1 1 0 0 1 1 1 1]\n",
      "expected results [0, 0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "(features, labels) = getLaughTracks(shuf=False, number_of_samples = 4, log=False)\n",
    "preds = predict(getModel('%s' % ('audio_2000')), 2, features)\n",
    "printResults(preds, [0, 0, 0, 0, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
