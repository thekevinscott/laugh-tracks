{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on laughter and not laughter\n",
      "samples/laughter/16-lfVsYaxc.wav\n",
      "samples/laughter/3IC76o_lhFw.wav\n",
      "samples/laughter/3LG9A7fUrPs.wav\n",
      "samples/laughter/4B06Bh3i8Ms.wav\n",
      "samples/laughter/4z12ijqiFrY.wav\n",
      "samples/laughter/At6oITvbENo.wav\n",
      "samples/laughter/C80iIItZHFM.wav\n",
      "samples/laughter/DZZORgAVFJw.wav\n",
      "samples/laughter/EzS7y_3GhKA.wav\n",
      "samples/laughter/IlMPU4AVU20.wav\n",
      "samples/laughter/Pz_DMUe4tXc.wav\n",
      "samples/laughter/R1hbmMfoT9c.wav\n",
      "samples/laughter/T_wNZhcw9x8.wav\n",
      "samples/laughter/b7KR9nQbhmQ.wav\n",
      "samples/laughter/bUTY_c6S3VI.wav\n",
      "samples/laughter/fVXpJNZYDH0.wav\n",
      "samples/laughter/iYVO5bUFww0.wav\n",
      "samples/laughter/mbgrSdRs9bQ.wav\n",
      "samples/laughter/nKo-dvnh6J0.wav\n",
      "samples/laughter/rHV09L1_t0g.wav\n",
      "samples/laughter/w0E3rEy4YPQ.wav\n",
      "samples/laughter/ySkafsRm9po.wav\n",
      "samples/notlaughter/-2QjmYDtjv8.wav\n",
      "samples/notlaughter/-ABggF-Eq-U.wav\n",
      "samples/notlaughter/-yUafzOXHPE.wav\n",
      "samples/notlaughter/2-OQhot_ml0.wav\n",
      "samples/notlaughter/2tOwd3p7TsE.wav\n",
      "samples/notlaughter/4kVGNFYjTH8.wav\n",
      "samples/notlaughter/8CdzyfNXcDI.wav\n",
      "samples/notlaughter/8OIH5gxUV1M.wav\n",
      "samples/notlaughter/Abggf-4fseY.wav\n",
      "samples/notlaughter/AiMPSc2nU-A.wav\n",
      "samples/notlaughter/DUFBEamEF0Q.wav\n",
      "samples/notlaughter/EguZb3oSBJs.wav\n",
      "samples/notlaughter/HvWhMI2wnPs.wav\n",
      "samples/notlaughter/TAqo-NZDuys.wav\n",
      "samples/notlaughter/Y3klZeiEkRY.wav\n",
      "samples/notlaughter/_zTpwNR5Bf4.wav\n",
      "samples/notlaughter/b0bUuVlesqw.wav\n",
      "samples/notlaughter/hg6f7hh67aw.wav\n",
      "samples/notlaughter/lRvqEjJ6yMU.wav\n",
      "samples/notlaughter/m7BgOYPNTlA.wav\n",
      "samples/notlaughter/pM8kz_r2vqw.wav\n",
      "samples/notlaughter/vJROVOsmz2I.wav\n",
      "samples/notlaughter/zqAKTEfFOII.wav\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "samples/laughter/16-lfVsYaxc.wav\n",
      "samples/laughter/3IC76o_lhFw.wav\n",
      "samples/laughter/3LG9A7fUrPs.wav\n",
      "samples/laughter/4B06Bh3i8Ms.wav\n",
      "samples/laughter/4z12ijqiFrY.wav\n",
      "samples/laughter/At6oITvbENo.wav\n",
      "samples/laughter/C80iIItZHFM.wav\n",
      "samples/laughter/DZZORgAVFJw.wav\n",
      "samples/laughter/EzS7y_3GhKA.wav\n",
      "samples/laughter/IlMPU4AVU20.wav\n",
      "samples/laughter/Pz_DMUe4tXc.wav\n",
      "samples/laughter/R1hbmMfoT9c.wav\n",
      "samples/laughter/T_wNZhcw9x8.wav\n",
      "samples/laughter/b7KR9nQbhmQ.wav\n",
      "samples/laughter/bUTY_c6S3VI.wav\n",
      "samples/laughter/fVXpJNZYDH0.wav\n",
      "samples/laughter/iYVO5bUFww0.wav\n",
      "samples/laughter/mbgrSdRs9bQ.wav\n",
      "samples/laughter/nKo-dvnh6J0.wav\n",
      "samples/laughter/rHV09L1_t0g.wav\n",
      "samples/laughter/w0E3rEy4YPQ.wav\n",
      "samples/laughter/ySkafsRm9po.wav\n",
      "number of samples 1\n",
      "reading 1 files\n",
      "['samples/laughter/3IC76o_lhFw.wav']\n",
      "returning 1 samples\n",
      "leaving behind 56 samples\n",
      "samples/notlaughter/-2QjmYDtjv8.wav\n",
      "samples/notlaughter/-ABggF-Eq-U.wav\n",
      "samples/notlaughter/-yUafzOXHPE.wav\n",
      "samples/notlaughter/2-OQhot_ml0.wav\n",
      "samples/notlaughter/2tOwd3p7TsE.wav\n",
      "samples/notlaughter/4kVGNFYjTH8.wav\n",
      "samples/notlaughter/8CdzyfNXcDI.wav\n",
      "samples/notlaughter/8OIH5gxUV1M.wav\n",
      "samples/notlaughter/Abggf-4fseY.wav\n",
      "samples/notlaughter/AiMPSc2nU-A.wav\n",
      "samples/notlaughter/DUFBEamEF0Q.wav\n",
      "samples/notlaughter/EguZb3oSBJs.wav\n",
      "samples/notlaughter/HvWhMI2wnPs.wav\n",
      "samples/notlaughter/TAqo-NZDuys.wav\n",
      "samples/notlaughter/Y3klZeiEkRY.wav\n",
      "samples/notlaughter/_zTpwNR5Bf4.wav\n",
      "samples/notlaughter/b0bUuVlesqw.wav\n",
      "samples/notlaughter/hg6f7hh67aw.wav\n",
      "samples/notlaughter/lRvqEjJ6yMU.wav\n",
      "samples/notlaughter/m7BgOYPNTlA.wav\n",
      "samples/notlaughter/pM8kz_r2vqw.wav\n",
      "samples/notlaughter/vJROVOsmz2I.wav\n",
      "samples/notlaughter/zqAKTEfFOII.wav\n",
      "number of samples 1\n",
      "reading 1 files\n",
      "['samples/notlaughter/2-OQhot_ml0.wav']\n",
      "returning 1 samples\n",
      "leaving behind 160 samples\n",
      "Step 1: loss 0.710581\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_1_1\n",
      "[[0.50876063 0.5981367 ]\n",
      " [0.4648213  0.617016  ]\n",
      " [0.48491955 0.62156403]\n",
      " [0.46897545 0.5927221 ]]\n",
      "[1 1 1 1]\n",
      "expected results [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg -y\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_pca_params.npz\n",
    "#installDeps()\n",
    "#!python vggish_train_demo.py --num_batches 50 --train_vggish=False --checkpoint './vggish_model.ckpt'\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioModel import predict, train\n",
    "from audioInput import getLaughTracks, getNoise\n",
    "\n",
    "def trainAndSaveAndPredict(test_data, number_of_classes = 2, number_of_samples = 1, epochs = 5, getData = getLaughTracks, use_cache = True, log = True):\n",
    "    def curriedGetSamples(shuf):\n",
    "        return getData(number_of_samples = number_of_samples, shuf = shuf, use_cache = use_cache, log = log)\n",
    "    model_name = 'model_%s_%s' % (number_of_samples, epochs)\n",
    "    preds = train(curriedGetSamples, number_of_classes, model_name = model_name, epochs = epochs)\n",
    "    \n",
    "\n",
    "    return predict(model_name, number_of_classes, test_data)\n",
    "\n",
    "def printResults(preds, expected = None): \n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        print(preds)\n",
    "        print(sess.run(tf.argmax(input=preds, axis=1))) \n",
    "        print('expected results', expected)\n",
    "\n",
    "def trainForNoise(number_of_samples=5, epochs=5):\n",
    "    use_cache = False\n",
    "    print('training on noise, sin, and constant waves')\n",
    "    (features, labels) = getNoise(shuf=False, number_of_samples = 2)\n",
    "    preds = trainAndSaveAndPredict(features, number_of_classes = 3, number_of_samples = number_of_samples, epochs = epochs, getData = getNoise)\n",
    "    printResults(preds, [0, 0, 1, 1, 2, 2])\n",
    "    \n",
    "def trainForLaughter(number_of_samples=5, epochs=5):  \n",
    "    use_cache = False\n",
    "    print('training on laughter and not laughter')\n",
    "    (features, labels) = getLaughTracks(shuf=False, number_of_samples = 2, use_cache = use_cache, use_full_files = False, log=False)\n",
    "    preds = trainAndSaveAndPredict(features, number_of_classes = 2, number_of_samples = number_of_samples, epochs = epochs, getData = getLaughTracks, use_cache = use_cache, log = True)\n",
    "    printResults(preds, [0, 0, 1, 1])\n",
    "    \n",
    "trainForLaughter(number_of_samples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on laughter and not laughter\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "number of samples 28\n",
      "reading 28 files\n",
      "['samples/laughter/EzS7y_3GhKA/yt.wav', 'samples/laughter/Pz_DMUe4tXc/yt.wav', 'samples/laughter/nKo-dvnh6J0/yt.wav', 'samples/laughter/3LG9A7fUrPs/prepared.wav', 'samples/laughter/4B06Bh3i8Ms/prepared.wav', 'samples/laughter/C80iIItZHFM/yt.wav', 'samples/laughter/EzS7y_3GhKA/prepared.wav', 'samples/laughter/bUTY_c6S3VI/yt.wav', 'samples/laughter/b7KR9nQbhmQ/yt.wav', 'samples/laughter/ySkafsRm9po/yt.wav', 'samples/laughter/nKo-dvnh6J0/prepared.wav', 'samples/laughter/w0E3rEy4YPQ/prepared.wav', 'samples/laughter/T_wNZhcw9x8/prepared.wav', 'samples/laughter/fVXpJNZYDH0/yt.wav', 'samples/laughter/4z12ijqiFrY/prepared.wav', 'samples/laughter/DZZORgAVFJw/prepared.wav', 'samples/laughter/C80iIItZHFM/prepared.wav', 'samples/laughter/16-lfVsYaxc/yt.wav', 'samples/laughter/b7KR9nQbhmQ/prepared.wav', 'samples/laughter/iYVO5bUFww0/prepared.wav', 'samples/laughter/mbgrSdRs9bQ/prepared.wav', 'samples/laughter/3LG9A7fUrPs/yt.wav', 'samples/laughter/rHV09L1_t0g/prepared.wav', 'samples/laughter/At6oITvbENo/prepared.wav', 'samples/laughter/ySkafsRm9po/prepared.wav', 'samples/laughter/w0E3rEy4YPQ/yt.wav', 'samples/laughter/iYVO5bUFww0/yt.wav', 'samples/laughter/bUTY_c6S3VI/prepared.wav']\n",
      "returning 28 samples\n",
      "leaving behind 2832 samples\n",
      "number of samples 28\n",
      "reading 28 files\n",
      "['samples/notlaughter/pM8kz_r2vqw/prepared.wav', 'samples/notlaughter/8CdzyfNXcDI/prepared.wav', 'samples/notlaughter/_zTpwNR5Bf4/yt.wav', 'samples/notlaughter/2-OQhot_ml0/yt.wav', 'samples/notlaughter/b0bUuVlesqw/yt.wav', 'samples/notlaughter/-yUafzOXHPE/prepared.wav', 'samples/notlaughter/8OIH5gxUV1M/prepared.wav', 'samples/notlaughter/8CdzyfNXcDI/yt.wav', 'samples/notlaughter/Y3klZeiEkRY/yt.wav', 'samples/notlaughter/Y3klZeiEkRY/prepared.wav', 'samples/notlaughter/EguZb3oSBJs/yt.wav', 'samples/notlaughter/4kVGNFYjTH8/yt.wav', 'samples/notlaughter/EguZb3oSBJs/prepared.wav', 'samples/notlaughter/2tOwd3p7TsE/prepared.wav', 'samples/notlaughter/m7BgOYPNTlA/prepared.wav', 'samples/notlaughter/b0bUuVlesqw/prepared.wav', 'samples/notlaughter/zqAKTEfFOII/yt.wav', 'samples/notlaughter/8OIH5gxUV1M/yt.wav', 'samples/notlaughter/Abggf-4fseY/prepared.wav', 'samples/notlaughter/DUFBEamEF0Q/yt.wav', 'samples/notlaughter/TAqo-NZDuys/yt.wav', 'samples/notlaughter/_zTpwNR5Bf4/prepared.wav', 'samples/notlaughter/-2QjmYDtjv8/prepared.wav', 'samples/notlaughter/hg6f7hh67aw/prepared.wav', 'samples/notlaughter/-ABggF-Eq-U/yt.wav', 'samples/notlaughter/lRvqEjJ6yMU/prepared.wav', 'samples/notlaughter/m7BgOYPNTlA/yt.wav', 'samples/notlaughter/-2QjmYDtjv8/yt.wav']\n",
      "returning 28 samples\n",
      "leaving behind 7103 samples\n",
      "Step 1: loss 0.687964\n",
      "number of samples 28\n",
      "reading 1 files\n",
      "['samples/laughter/At6oITvbENo_yt.wav/samples/laughter/At6oITvbENo_yt.wav']\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'samples/laughter/At6oITvbENo_yt.wav/samples/laughter/At6oITvbENo_yt.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d0367e024416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainForLaughter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b4b3a0e064c4>\u001b[0m in \u001b[0;36mtrainForLaughter\u001b[0;34m(number_of_samples, epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training on laughter and not laughter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLaughTracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_full_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainAndSaveAndPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLaughTracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprintResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b4b3a0e064c4>\u001b[0m in \u001b[0;36mtrainAndSaveAndPredict\u001b[0;34m(test_data, number_of_classes, number_of_samples, epochs, getData, use_cache, log)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_%s_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurriedGetSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioModel.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(get_examples, number_of_classes, model_name, epochs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# The training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             [num_steps, loss, _] = sess.run(\n\u001b[1;32m     86\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b4b3a0e064c4>\u001b[0m in \u001b[0;36mcurriedGetSamples\u001b[0;34m(shuf)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainAndSaveAndPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLaughTracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcurriedGetSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_%s_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurriedGetSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetLaughTracks\u001b[0;34m(number_of_samples, shuf, use_cache, use_full_files, log)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m#print('not using cache for laugh tracks')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laughter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'notlaughter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_full_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_full_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints/features_%s.npy'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints/labels_%s.npy'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetSamples\u001b[0;34m(classes, shuf, number_of_samples, use_full_files, log)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFilePathsForClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_full_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetOneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mwhys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(files, number_of_samples, shuf, use_full_files, log, arr)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSamplesForFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_full_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetSamplesForFiles\u001b[0;34m(files, number_of_samples, use_full_files, log)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSampleForFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetSampleForFile\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetSampleForFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# accepts a numpy array representing a single audio file, or multiple files concat'ed together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pydub/utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'samples/laughter/At6oITvbENo_yt.wav/samples/laughter/At6oITvbENo_yt.wav'"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=28, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
