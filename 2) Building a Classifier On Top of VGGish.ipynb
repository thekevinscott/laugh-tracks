{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg -y\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_pca_params.npz\n",
    "#installDeps()\n",
    "#!python vggish_train_demo.py --num_batches 50 --train_vggish=False --checkpoint './vggish_model.ckpt'\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioModel import predict, train\n",
    "from audioInput import getLaughTracks, getNoise\n",
    "\n",
    "def trainAndSaveAndPredict(test_data, model, number_of_classes = 2, number_of_samples = 1, epochs = 5, getData = getLaughTracks, use_cache = True, log = True):\n",
    "    model_name = '%s_%s' % (model, number_of_samples)\n",
    "    def curriedGetSamples(shuf):\n",
    "        return getData(number_of_samples = number_of_samples, shuf = shuf, use_cache = use_cache, log = log)\n",
    "    preds = train(curriedGetSamples, number_of_classes, model_name = model_name, epochs = epochs)\n",
    "    \n",
    "    return predict('%s_%s-%s' % (model_name, epochs, epochs), number_of_classes, test_data)\n",
    "\n",
    "def printResults(preds, expected = None): \n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        print(preds)\n",
    "        print(sess.run(tf.argmax(input=preds, axis=1))) \n",
    "        print('expected results', expected)\n",
    "\n",
    "def trainForNoise(number_of_samples=5, epochs=5):\n",
    "    use_cache = False\n",
    "    print('training on noise, sin, and constant waves')\n",
    "    (features, labels) = getNoise(shuf=False, number_of_samples = 2)\n",
    "    preds = trainAndSaveAndPredict(features, 'noise', number_of_classes = 3, number_of_samples = number_of_samples, epochs = epochs, getData = getNoise)\n",
    "    printResults(preds, [0, 0, 1, 1, 2, 2])\n",
    "    \n",
    "def trainForLaughter(number_of_samples=5, epochs=5):  \n",
    "    use_cache = False\n",
    "    #print('training on laughter and not laughter')\n",
    "    (features, labels) = getLaughTracks(shuf=False, number_of_samples = 2, use_cache = use_cache, log=False)\n",
    "    preds = trainAndSaveAndPredict(features, 'audio', number_of_classes = 2, number_of_samples = number_of_samples, epochs = epochs, getData = getLaughTracks, use_cache = use_cache, log = False)\n",
    "    printResults(preds, [0, 0, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.72361\n",
      "loading ./model/audio_1_1-1/model\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/audio_1_1-1/model\n",
      "[[0.58894306 0.63782966]\n",
      " [0.60774016 0.63660455]\n",
      " [0.56984234 0.6090671 ]\n",
      " [0.5945718  0.6311385 ]]\n",
      "[1 1 1 1]\n",
      "expected results [0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range (0, 30):\n",
    "#    number_of_samples = 1006 + (i * 1)\n",
    "#    trainForLaughter(number_of_samples=number_of_samples, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "Step 1: loss 0.690164\n",
      "Step 2: loss 0.665999\n",
      "Step 3: loss 0.634396\n",
      "Step 4: loss 0.612395\n",
      "Step 5: loss 0.532513\n",
      "Step 6: loss 0.570745\n",
      "Step 7: loss 0.567581\n",
      "Step 8: loss 0.537245\n",
      "Step 9: loss 0.458661\n",
      "Step 10: loss 0.467219\n",
      "Step 11: loss 0.603286\n",
      "Step 12: loss 0.433018\n",
      "Step 13: loss 0.388321\n",
      "Step 14: loss 0.412329\n",
      "Step 15: loss 0.447394\n",
      "Step 16: loss 0.390374\n",
      "Step 17: loss 0.337031\n",
      "Step 18: loss 0.381813\n",
      "Step 19: loss 0.298182\n",
      "Step 20: loss 0.337973\n",
      "Step 21: loss 0.275488\n",
      "Step 22: loss 0.278766\n",
      "Step 23: loss 0.266147\n",
      "Step 24: loss 0.328608\n",
      "Step 25: loss 0.186947\n",
      "Step 26: loss 0.211109\n",
      "Step 27: loss 0.263777\n",
      "Step 28: loss 0.235831\n",
      "Step 29: loss 0.198745\n",
      "Step 30: loss 0.329258\n",
      "Step 31: loss 0.303927\n",
      "Step 32: loss 0.231897\n",
      "Step 33: loss 0.202584\n",
      "Step 34: loss 0.34923\n",
      "Step 35: loss 0.100973\n",
      "Step 36: loss 0.0894409\n",
      "Step 37: loss 0.328973\n",
      "Step 38: loss 0.131816\n",
      "Step 39: loss 0.212398\n",
      "Step 40: loss 0.300236\n",
      "Step 41: loss 0.184675\n",
      "Step 42: loss 0.109297\n",
      "Step 43: loss 0.0757249\n",
      "Step 44: loss 0.158834\n",
      "Step 45: loss 0.190329\n",
      "Step 46: loss 0.196614\n",
      "Step 47: loss 0.168345\n",
      "Step 48: loss 0.355138\n",
      "Step 49: loss 0.129321\n",
      "Step 50: loss 0.183588\n",
      "Step 51: loss 0.209971\n",
      "Step 52: loss 0.211287\n",
      "Step 53: loss 0.231861\n",
      "Step 54: loss 0.180258\n",
      "Step 55: loss 0.144643\n",
      "Step 56: loss 0.262686\n",
      "Step 57: loss 0.106085\n",
      "Step 58: loss 0.171967\n",
      "Step 59: loss 0.180076\n",
      "Step 60: loss 0.123396\n",
      "Step 61: loss 0.241245\n",
      "Step 62: loss 0.163805\n",
      "Step 63: loss 0.0959683\n",
      "Step 64: loss 0.175487\n",
      "Step 65: loss 0.318867\n",
      "Step 66: loss 0.184813\n",
      "Step 67: loss 0.164426\n",
      "Step 68: loss 0.287776\n",
      "Step 69: loss 0.219145\n",
      "Step 70: loss 0.312254\n",
      "Step 71: loss 0.328317\n",
      "Step 72: loss 0.0434254\n",
      "Step 73: loss 0.131514\n",
      "Step 74: loss 0.164935\n",
      "Step 75: loss 0.139093\n",
      "Step 76: loss 0.32027\n",
      "Step 77: loss 0.112422\n",
      "Step 78: loss 0.201738\n",
      "Step 79: loss 0.225014\n",
      "Step 80: loss 0.338811\n",
      "Step 81: loss 0.160533\n",
      "Step 82: loss 0.16778\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=500, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
