{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg -y\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "    #!wget https://storage.googleapis.com/audioset/vggish_pca_params.npz\n",
    "#installDeps()\n",
    "#!python vggish_train_demo.py --num_batches 50 --train_vggish=False --checkpoint './vggish_model.ckpt'\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioModel import predict, train\n",
    "from audioInput import getLaughTracks, getNoise\n",
    "\n",
    "def trainAndSaveAndPredict(test_data, number_of_classes = 2, number_of_samples = 1, epochs = 5, getData = getLaughTracks, use_cache = True, log = True):\n",
    "    def curriedGetSamples(shuf):\n",
    "        return getData(number_of_samples = number_of_samples, shuf = shuf, use_cache = use_cache, log = log)\n",
    "    model_name = 'model_%s_%s' % (number_of_samples, epochs)\n",
    "    preds = train(curriedGetSamples, number_of_classes, model_name = model_name, epochs = epochs)\n",
    "    \n",
    "\n",
    "    return predict(model_name, number_of_classes, test_data)\n",
    "\n",
    "def printResults(preds, expected = None): \n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        print(preds)\n",
    "        print(sess.run(tf.argmax(input=preds, axis=1))) \n",
    "        print('expected results', expected)\n",
    "\n",
    "def trainForNoise(number_of_samples=5, epochs=5):\n",
    "    use_cache = False\n",
    "    print('training on noise, sin, and constant waves')\n",
    "    (features, labels) = getNoise(shuf=False, number_of_samples = 2)\n",
    "    preds = trainAndSaveAndPredict(features, number_of_classes = 3, number_of_samples = number_of_samples, epochs = epochs, getData = getNoise)\n",
    "    printResults(preds, [0, 0, 1, 1, 2, 2])\n",
    "    \n",
    "def trainForLaughter(number_of_samples=5, epochs=5):  \n",
    "    use_cache = False\n",
    "    #print('training on laughter and not laughter')\n",
    "    (features, labels) = getLaughTracks(shuf=False, number_of_samples = 2, use_cache = use_cache, log=False)\n",
    "    preds = trainAndSaveAndPredict(features, number_of_classes = 2, number_of_samples = number_of_samples, epochs = epochs, getData = getLaughTracks, use_cache = use_cache, log = False)\n",
    "    #printResults(preds, [0, 0, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "number of samples 950 reading 22 files ['samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/R1hbmMfoT9c.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/hg6f7hh67aw.wav', 'samples/notlaughter/DUFBEamEF0Q.wav', 'samples/notlaughter/b0bUuVlesqw.wav']\n",
      "Step 1: loss 0.756288\n",
      "number of samples 950 reading 22 files ['samples/laughter/C80iIItZHFM.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/IlMPU4AVU20.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/m7BgOYPNTlA.wav', 'samples/notlaughter/pM8kz_r2vqw.wav', 'samples/notlaughter/8OIH5gxUV1M.wav']\n",
      "Step 3: loss 0.684908\n",
      "number of samples 950 reading 22 files ['samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/C80iIItZHFM.wav', 'samples/laughter/rHV09L1_t0g.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/8OIH5gxUV1M.wav', 'samples/notlaughter/Y3klZeiEkRY.wav', 'samples/notlaughter/8CdzyfNXcDI.wav']\n",
      "Step 4: loss 0.680326\n",
      "number of samples 950 reading 22 files ['samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/ySkafsRm9po.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/8OIH5gxUV1M.wav', 'samples/notlaughter/b0bUuVlesqw.wav', 'samples/notlaughter/lRvqEjJ6yMU.wav']\n",
      "Step 5: loss 0.669916\n",
      "number of samples 950 reading 22 files ['samples/laughter/C80iIItZHFM.wav', 'samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/At6oITvbENo.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/m7BgOYPNTlA.wav', 'samples/notlaughter/TAqo-NZDuys.wav', 'samples/notlaughter/b0bUuVlesqw.wav']\n",
      "Step 6: loss 0.656716\n",
      "number of samples 950 reading 22 files ['samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/mbgrSdRs9bQ.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/b0bUuVlesqw.wav', 'samples/notlaughter/Y3klZeiEkRY.wav', 'samples/notlaughter/2tOwd3p7TsE.wav']\n",
      "Step 7: loss 0.645276\n",
      "number of samples 950 reading 22 files ['samples/laughter/ySkafsRm9po.wav', 'samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/At6oITvbENo.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/Y3klZeiEkRY.wav', 'samples/notlaughter/-yUafzOXHPE.wav', 'samples/notlaughter/4kVGNFYjTH8.wav']\n",
      "Step 8: loss 0.638349\n",
      "number of samples 950 reading 22 files ['samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/C80iIItZHFM.wav', 'samples/laughter/iYVO5bUFww0.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/m7BgOYPNTlA.wav', 'samples/notlaughter/pM8kz_r2vqw.wav', 'samples/notlaughter/DUFBEamEF0Q.wav']\n",
      "Step 9: loss 0.632587\n",
      "number of samples 950 reading 22 files ['samples/laughter/3LG9A7fUrPs.wav', 'samples/laughter/At6oITvbENo.wav', 'samples/laughter/IlMPU4AVU20.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/Y3klZeiEkRY.wav', 'samples/notlaughter/zqAKTEfFOII.wav', 'samples/notlaughter/8OIH5gxUV1M.wav']\n",
      "Step 10: loss 0.611164\n",
      "number of samples 950 reading 22 files ['samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/At6oITvbENo.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/-yUafzOXHPE.wav', 'samples/notlaughter/b0bUuVlesqw.wav', 'samples/notlaughter/HvWhMI2wnPs.wav']\n",
      "Step 11: loss 0.562128\n",
      "number of samples 950 reading 22 files ['samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/C80iIItZHFM.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/AiMPSc2nU-A.wav', 'samples/notlaughter/DUFBEamEF0Q.wav', 'samples/notlaughter/8CdzyfNXcDI.wav']\n",
      "Step 12: loss 0.594259\n",
      "number of samples 950 reading 22 files ['samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/3LG9A7fUrPs.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/zqAKTEfFOII.wav', 'samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/EguZb3oSBJs.wav']\n",
      "Step 13: loss 0.559084\n",
      "number of samples 950 reading 22 files ['samples/laughter/mbgrSdRs9bQ.wav', 'samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/iYVO5bUFww0.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/b0bUuVlesqw.wav', 'samples/notlaughter/-2QjmYDtjv8.wav', 'samples/notlaughter/_zTpwNR5Bf4.wav']\n",
      "Step 14: loss 0.529935\n",
      "number of samples 950 reading 22 files ['samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/At6oITvbENo.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/4kVGNFYjTH8.wav', 'samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/lRvqEjJ6yMU.wav']\n",
      "Step 15: loss 0.542328\n",
      "number of samples 950 reading 22 files ['samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/C80iIItZHFM.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/Y3klZeiEkRY.wav', 'samples/notlaughter/AiMPSc2nU-A.wav', 'samples/notlaughter/8OIH5gxUV1M.wav']\n",
      "Step 16: loss 0.511756\n",
      "number of samples 950 reading 22 files ['samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/4B06Bh3i8Ms.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/8OIH5gxUV1M.wav', 'samples/notlaughter/-ABggF-Eq-U.wav']\n",
      "Step 17: loss 0.514273\n",
      "number of samples 950 reading 22 files ['samples/laughter/ySkafsRm9po.wav', 'samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/rHV09L1_t0g.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/Abggf-4fseY.wav', 'samples/notlaughter/m7BgOYPNTlA.wav']\n",
      "Step 18: loss 0.45192\n",
      "number of samples 950 reading 22 files ['samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/EzS7y_3GhKA.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/-2QjmYDtjv8.wav', 'samples/notlaughter/2tOwd3p7TsE.wav', 'samples/notlaughter/8CdzyfNXcDI.wav']\n",
      "Step 19: loss 0.466659\n",
      "number of samples 950 reading 22 files ['samples/laughter/bUTY_c6S3VI.wav', 'samples/laughter/mbgrSdRs9bQ.wav', 'samples/laughter/R1hbmMfoT9c.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/-2QjmYDtjv8.wav', 'samples/notlaughter/lRvqEjJ6yMU.wav', 'samples/notlaughter/Abggf-4fseY.wav']\n",
      "Step 20: loss 0.422151\n",
      "number of samples 950 reading 22 files ['samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/DZZORgAVFJw.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/TAqo-NZDuys.wav', 'samples/notlaughter/DUFBEamEF0Q.wav', 'samples/notlaughter/-ABggF-Eq-U.wav']\n",
      "Step 21: loss 0.449379\n",
      "number of samples 950 reading 22 files ['samples/laughter/C80iIItZHFM.wav', 'samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/Pz_DMUe4tXc.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/Abggf-4fseY.wav', 'samples/notlaughter/2tOwd3p7TsE.wav', 'samples/notlaughter/hg6f7hh67aw.wav']\n",
      "Step 22: loss 0.351651\n",
      "number of samples 950 reading 22 files ['samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/Pz_DMUe4tXc.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/DUFBEamEF0Q.wav', 'samples/notlaughter/TAqo-NZDuys.wav', 'samples/notlaughter/m7BgOYPNTlA.wav']\n",
      "Step 23: loss 0.395122\n",
      "number of samples 950 reading 22 files ['samples/laughter/3LG9A7fUrPs.wav', 'samples/laughter/w0E3rEy4YPQ.wav', 'samples/laughter/C80iIItZHFM.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/8OIH5gxUV1M.wav', 'samples/notlaughter/AiMPSc2nU-A.wav']\n",
      "Step 24: loss 0.380439\n",
      "number of samples 950 reading 22 files ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/4B06Bh3i8Ms.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/8CdzyfNXcDI.wav', 'samples/notlaughter/TAqo-NZDuys.wav', 'samples/notlaughter/_zTpwNR5Bf4.wav']\n",
      "Step 25: loss 0.388388\n",
      "number of samples 950 reading 22 files ['samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/3LG9A7fUrPs.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/pM8kz_r2vqw.wav', 'samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/hg6f7hh67aw.wav']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26: loss 0.319671\n",
      "number of samples 950 reading 22 files ['samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/R1hbmMfoT9c.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/m7BgOYPNTlA.wav', 'samples/notlaughter/_zTpwNR5Bf4.wav', 'samples/notlaughter/hg6f7hh67aw.wav']\n",
      "Step 27: loss 0.325721\n",
      "number of samples 950 reading 22 files ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/ySkafsRm9po.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/_zTpwNR5Bf4.wav', 'samples/notlaughter/-yUafzOXHPE.wav', 'samples/notlaughter/2tOwd3p7TsE.wav']\n",
      "Step 28: loss 0.270524\n",
      "number of samples 950 reading 22 files ['samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/ySkafsRm9po.wav', 'samples/laughter/mbgrSdRs9bQ.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/TAqo-NZDuys.wav', 'samples/notlaughter/2tOwd3p7TsE.wav', 'samples/notlaughter/b0bUuVlesqw.wav']\n",
      "Step 29: loss 0.296177\n",
      "number of samples 950 reading 22 files ['samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/Pz_DMUe4tXc.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/AiMPSc2nU-A.wav', 'samples/notlaughter/Abggf-4fseY.wav', 'samples/notlaughter/2tOwd3p7TsE.wav']\n",
      "Step 30: loss 0.214411\n",
      "number of samples 950 reading 22 files ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/4B06Bh3i8Ms.wav', 'samples/laughter/mbgrSdRs9bQ.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/4kVGNFYjTH8.wav', 'samples/notlaughter/2-OQhot_ml0.wav', 'samples/notlaughter/hg6f7hh67aw.wav']\n",
      "Step 31: loss 0.281446\n",
      "number of samples 950 reading 22 files ['samples/laughter/w0E3rEy4YPQ.wav', 'samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/T_wNZhcw9x8.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/2tOwd3p7TsE.wav', 'samples/notlaughter/m7BgOYPNTlA.wav', 'samples/notlaughter/vJROVOsmz2I.wav']\n",
      "Step 32: loss 0.271757\n",
      "number of samples 950 reading 22 files ['samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/rHV09L1_t0g.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/-2QjmYDtjv8.wav', 'samples/notlaughter/HvWhMI2wnPs.wav', 'samples/notlaughter/8CdzyfNXcDI.wav']\n",
      "Step 33: loss 0.321197\n",
      "number of samples 950 reading 22 files ['samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/ySkafsRm9po.wav', 'samples/laughter/Pz_DMUe4tXc.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/4kVGNFYjTH8.wav', 'samples/notlaughter/pM8kz_r2vqw.wav', 'samples/notlaughter/AiMPSc2nU-A.wav']\n",
      "Step 34: loss 0.246596\n",
      "number of samples 950 reading 22 files ['samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/w0E3rEy4YPQ.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/8CdzyfNXcDI.wav', 'samples/notlaughter/TAqo-NZDuys.wav', 'samples/notlaughter/-ABggF-Eq-U.wav']\n",
      "Step 35: loss 0.257811\n",
      "number of samples 950 reading 22 files ['samples/laughter/C80iIItZHFM.wav', 'samples/laughter/b7KR9nQbhmQ.wav', 'samples/laughter/IlMPU4AVU20.wav']\n",
      "number of samples 950 reading 23 files ['samples/notlaughter/AiMPSc2nU-A.wav', 'samples/notlaughter/m7BgOYPNTlA.wav', 'samples/notlaughter/Y3klZeiEkRY.wav']\n"
     ]
    }
   ],
   "source": [
    "trainForLaughter(number_of_samples=970, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "number of samples 1006 reading 22 files ['samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/3IC76o_lhFw.wav']\n",
      "number of samples 1006 reading 23 files ['samples/notlaughter/2tOwd3p7TsE.wav', 'samples/notlaughter/pM8kz_r2vqw.wav', 'samples/notlaughter/zqAKTEfFOII.wav']\n"
     ]
    }
   ],
   "source": [
    "#for i in range (0, 30):\n",
    "#    number_of_samples = 1006 + (i * 1)\n",
    "#    trainForLaughter(number_of_samples=number_of_samples, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
