{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "1 ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/3LG9A7fUrPs.wav', 'samples/laughter/4B06Bh3i8Ms.wav', 'samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/At6oITvbENo.wav', 'samples/laughter/C80iIItZHFM.wav', 'samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/b7KR9nQbhmQ.wav', 'samples/laughter/bUTY_c6S3VI.wav', 'samples/laughter/fVXpJNZYDH0.wav', 'samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/mbgrSdRs9bQ.wav', 'samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/rHV09L1_t0g.wav', 'samples/laughter/snl 2 laughter.wav', 'samples/laughter/standup 1 laughter.wav', 'samples/laughter/standup 2 laughter.wav', 'samples/laughter/ultimate_1_a.wav', 'samples/laughter/ultimate_2_a.wav', 'samples/laughter/w0E3rEy4YPQ.wav', 'samples/laughter/ySkafsRm9po.wav']\n",
      "file failed ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/3LG9A7fUrPs.wav', 'samples/laughter/4B06Bh3i8Ms.wav', 'samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/At6oITvbENo.wav', 'samples/laughter/C80iIItZHFM.wav', 'samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/b7KR9nQbhmQ.wav', 'samples/laughter/bUTY_c6S3VI.wav', 'samples/laughter/fVXpJNZYDH0.wav', 'samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/mbgrSdRs9bQ.wav', 'samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/rHV09L1_t0g.wav', 'samples/laughter/snl 2 laughter.wav', 'samples/laughter/standup 1 laughter.wav', 'samples/laughter/standup 2 laughter.wav', 'samples/laughter/ultimate_1_a.wav', 'samples/laughter/ultimate_2_a.wav', 'samples/laughter/w0E3rEy4YPQ.wav', 'samples/laughter/ySkafsRm9po.wav']\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "file failed: ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/3LG9A7fUrPs.wav', 'samples/laughter/4B06Bh3i8Ms.wav', 'samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/At6oITvbENo.wav', 'samples/laughter/C80iIItZHFM.wav', 'samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/b7KR9nQbhmQ.wav', 'samples/laughter/bUTY_c6S3VI.wav', 'samples/laughter/fVXpJNZYDH0.wav', 'samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/mbgrSdRs9bQ.wav', 'samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/rHV09L1_t0g.wav', 'samples/laughter/snl 2 laughter.wav', 'samples/laughter/standup 1 laughter.wav', 'samples/laughter/standup 2 laughter.wav', 'samples/laughter/ultimate_1_a.wav', 'samples/laughter/ultimate_2_a.wav', 'samples/laughter/w0E3rEy4YPQ.wav', 'samples/laughter/ySkafsRm9po.wav']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetSamplesForFile\u001b[0;34m(file, seconds)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mstdin_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0mstdin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-523dfc4c200d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#trainForLaughter(epochs=1, number_of_samples=None, batch_size=32, lr=vggish_params.LEARNING_RATE / 400)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetLaughTracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/laugh-tracks/audioModel.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(get_examples, number_of_classes, model_name, epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mymodel/train_op'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mVALIDATION_SPLIT\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetLaughTracks\u001b[0;34m(shuf, split)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetLaughTracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetSamples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laughter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'notlaughter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetSamples\u001b[0;34m(classes, shuf)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFilePathsForClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mfoundFiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfilesData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetOneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilesData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(files, arr)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mfileSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSamplesForFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0mzippedUp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileSamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/laugh-tracks/audioInput.py\u001b[0m in \u001b[0;36mgetSamplesForFile\u001b[0;34m(file, seconds)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file failed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file failed: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# accepts a numpy array representing a single audio file, or multiple files concat'ed together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: file failed: ['samples/laughter/16-lfVsYaxc.wav', 'samples/laughter/3IC76o_lhFw.wav', 'samples/laughter/3LG9A7fUrPs.wav', 'samples/laughter/4B06Bh3i8Ms.wav', 'samples/laughter/4z12ijqiFrY.wav', 'samples/laughter/At6oITvbENo.wav', 'samples/laughter/C80iIItZHFM.wav', 'samples/laughter/DZZORgAVFJw.wav', 'samples/laughter/EzS7y_3GhKA.wav', 'samples/laughter/IlMPU4AVU20.wav', 'samples/laughter/Pz_DMUe4tXc.wav', 'samples/laughter/R1hbmMfoT9c.wav', 'samples/laughter/T_wNZhcw9x8.wav', 'samples/laughter/b7KR9nQbhmQ.wav', 'samples/laughter/bUTY_c6S3VI.wav', 'samples/laughter/fVXpJNZYDH0.wav', 'samples/laughter/iYVO5bUFww0.wav', 'samples/laughter/mbgrSdRs9bQ.wav', 'samples/laughter/nKo-dvnh6J0.wav', 'samples/laughter/rHV09L1_t0g.wav', 'samples/laughter/snl 2 laughter.wav', 'samples/laughter/standup 1 laughter.wav', 'samples/laughter/standup 2 laughter.wav', 'samples/laughter/ultimate_1_a.wav', 'samples/laughter/ultimate_2_a.wav', 'samples/laughter/w0E3rEy4YPQ.wav', 'samples/laughter/ySkafsRm9po.wav']"
     ]
    }
   ],
   "source": [
    "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "from __future__ import print_function\n",
    "\n",
    "def installDeps():\n",
    "    !pip install numpy scipy\n",
    "    !pip install resampy tensorflow six\n",
    "    !pip install youtube_dl\n",
    "    !pip install ipywidgets\n",
    "    !pip install pydub\n",
    "    !pip install tqdm\n",
    "    !pip install ffmpeg-python\n",
    "    !apt-get install ffmpeg -y\n",
    "#installDeps()\n",
    "\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "from pydub import AudioSegment\n",
    "from audioModel import predict, train, accuracy, getCorrectAndIncorrect\n",
    "from audioInput import getLaughTracks, getNoise, getSamples\n",
    "from audioUtils import readFolder\n",
    "\n",
    "def getModel(path):\n",
    "    files = readFolder('model/%s' % path)\n",
    "    if len(files) > 0:\n",
    "        return '%s/%s' % (path, files[0])\n",
    "    return None\n",
    "\n",
    "def trainAndSaveAndPredict(test_data, model, number_of_classes = 2, number_of_samples = None, epochs = 5, getData = getLaughTracks, log = True, batch_size = 32, lr = vggish_params.LEARNING_RATE):\n",
    "    model_name = '%s_%s' % (model, number_of_samples)\n",
    "\n",
    "    def curriedGetSamples(shuf):\n",
    "        return getData(number_of_samples = number_of_samples, shuf = shuf, log = log)\n",
    "    #print('model_name', model_name)\n",
    "    print('---')\n",
    "    preds = train(curriedGetSamples, number_of_classes, model_name = model_name, epochs = epochs, batch_size = batch_size)\n",
    "    \n",
    "    return predict(getModel('%s' % (model_name)), number_of_classes, test_data)\n",
    "\n",
    "def printResults(preds, labels): \n",
    "    correct = []\n",
    "    incorrect = []\n",
    "    print('accuracy', accuracy(preds, labels))\n",
    "    getCorrectAndIncorrect(preds, labels)\n",
    "    correct, incorrect = getCorrectAndIncorrect(preds, labels)\n",
    "    print(correct[0:5])\n",
    "    print(incorrect[0:5])\n",
    "    return correct, incorrect\n",
    "    \n",
    "def trainForNoise(number_of_samples=5, epochs=5):\n",
    "    print('training on noise, sin, and constant waves')\n",
    "    (features, labels) = getNoise(shuf=False, number_of_samples = 2)\n",
    "    preds = trainAndSaveAndPredict(features, 'noise', number_of_classes = 3, number_of_samples = number_of_samples, epochs = epochs, getData = getNoise, lr = vggish_params.LEARNING_RATE)\n",
    "    printResults(preds, [0, 0, 1, 1, 2, 2])\n",
    "    \n",
    "def trainForLaughter(number_of_samples=None, epochs=5, batch_size = 32, lr = vggish_params.LEARNING_RATE):  \n",
    "    #print('training on laughter and not laughter')\n",
    "    (features, labels, chunks) = getSamples(['laughter-test', 'notlaughter-test'], shuf = False)\n",
    "    preds = trainAndSaveAndPredict(features, 'audio', number_of_classes = 2, epochs = epochs, getData = getLaughTracks, batch_size = batch_size, lr = lr)\n",
    "    printResults(preds, labels)\n",
    "    return preds, labels\n",
    "\n",
    "model_name = '%s_%s' % ('audio', None)\n",
    "#trainForLaughter(epochs=1, number_of_samples=None, batch_size=32, lr=vggish_params.LEARNING_RATE / 400)\n",
    "train(getLaughTracks, 2, model_name = model_name, epochs = 1, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features per class {'notlaughter-test': 824, 'laughter-test': 276}\n",
      "---\n",
      "INFO:tensorflow:Restoring parameters from ./vggish_model.ckpt\n",
      "no cache file available, building one\n",
      "Number of features per class {'notlaughter': 8383, 'laughter': 9003}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 251/487 [05:42<05:17,  1.34s/it]"
     ]
    }
   ],
   "source": [
    "trainForLaughter(epochs=20, number_of_samples=None, batch_size=32, lr=vggish_params.LEARNING_RATE / 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 64) [1. 0.]\n",
      "(1, 96, 64) [0. 1.]\n",
      "Number of features per class {'laughter-test': 1, 'notlaughter-test': 1}\n",
      "(2, 96, 64)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "(features, labels) = getSamples(['laughter-test', 'notlaughter-test'], shuf = False, number_of_samples = 1, log=False, use_cache = False, get_vgg = True)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44100,) [1. 0.]\n",
      "chunks 1\n",
      "(44100,) [0. 1.]\n",
      "chunks 1\n",
      "Number of features per class {'laughter-test': 44100, 'notlaughter-test': 44100}\n",
      "(88200,)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "(features, labels) = getSamples(['laughter-test', 'notlaughter-test'], shuf = False, number_of_samples = 1, log=False, get_vgg = False, use_cache = False)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
